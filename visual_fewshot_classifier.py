#!/usr/bin/env python3
"""
Visual Few-Shot äº¤é€šæ ‡å¿—åˆ†ç±»å™¨

ä½¿ç”¨è§†è§‰å¯¹æ¯”æ–¹å¼ï¼ŒæŠŠæ ‡å‡†å›¾æ‹¼æˆç½‘æ ¼è®© GLM-4.6V ç›´æ¥å¯¹æ¯”è¯†åˆ«ã€‚
æ¯”çº¯æ–‡æœ¬ RAG æ›´å‡†ç¡®ï¼Œèƒ½åŒºåˆ†"é™é€Ÿ50"å’Œ"é™é€Ÿ60"ã€‚

ç”¨æ³•:
    python3 visual_fewshot_classifier.py --test test_images/extracted_frames/D1_frame_0006.jpg
"""

import os
import base64
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from zai import ZaiClient


# ============================================================================
# æ ‡å‡†å›¾åº“é…ç½®
# ============================================================================

STANDARDS_DIR = Path("examples/signs/highres/png2560px")

# æŒ‰ç±»åˆ«ç»„ç»‡æ ‡å¿—ï¼ˆåŸºäºæ–‡ä»¶åå…³é”®è¯ï¼‰
SIGN_CATEGORIES = {
    "speed_limit": ["Speed_limit", "Variable_speed"],
    "prohibition": ["No_", "Prohibit", "End_of"],
    "warning": ["ahead", "Cattle", "Children", "Cyclist", "Danger", "Fog", "Horses"],
    "direction": ["Direction", "Turn", "Keep", "Ahead_only", "One_way"],
    "distance": ["Countdown", "Distance", "100m", "200m", "300m"],
    "bus_lane": ["Bus_lane", "bus_lane"],
    "other": []  # é»˜è®¤
}


def get_sign_category(filename: str) -> str:
    """æ ¹æ®æ–‡ä»¶ååˆ¤æ–­æ ‡å¿—ç±»åˆ«"""
    for cat, keywords in SIGN_CATEGORIES.items():
        for kw in keywords:
            if kw.lower() in filename.lower():
                return cat
    return "other"


def load_standard_signs() -> dict:
    """åŠ è½½æ‰€æœ‰æ ‡å‡†æ ‡å¿—å¹¶æŒ‰ç±»åˆ«åˆ†ç»„"""
    if not STANDARDS_DIR.exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ ‡å‡†å›¾åº“: {STANDARDS_DIR}")
        return {}
    
    signs_by_category = {cat: [] for cat in SIGN_CATEGORIES}
    
    for f in sorted(STANDARDS_DIR.glob("*.png")):
        cat = get_sign_category(f.stem)
        signs_by_category[cat].append({
            "name": f.stem,
            "path": str(f)
        })
    
    return signs_by_category


def create_grid_image(images: list, labels: list, cols: int = 4, cell_size: int = 150) -> Image.Image:
    """
    æŠŠå¤šå¼ å›¾ç‰‡æ‹¼æˆç½‘æ ¼å›¾
    
    Args:
        images: PIL Image åˆ—è¡¨
        labels: æ¯å¼ å›¾çš„æ ‡ç­¾ï¼ˆA, B, C...ï¼‰
        cols: æ¯è¡Œå¤šå°‘åˆ—
        cell_size: æ¯ä¸ªæ ¼å­çš„å¤§å°
    
    Returns:
        æ‹¼æ¥å¥½çš„ç½‘æ ¼å›¾
    """
    rows = (len(images) + cols - 1) // cols
    
    # åˆ›å»ºç”»å¸ƒ
    grid_width = cols * cell_size
    grid_height = rows * cell_size
    grid = Image.new("RGB", (grid_width, grid_height), (255, 255, 255))
    draw = ImageDraw.Draw(grid)
    
    for i, (img, label) in enumerate(zip(images, labels)):
        row = i // cols
        col = i % cols
        
        # ç¼©æ”¾å›¾ç‰‡
        img_resized = img.copy()
        img_resized.thumbnail((cell_size - 20, cell_size - 30), Image.Resampling.LANCZOS)
        
        # è®¡ç®—ä½ç½®ï¼ˆå±…ä¸­ï¼‰
        x = col * cell_size + (cell_size - img_resized.width) // 2
        y = row * cell_size + 20 + (cell_size - 30 - img_resized.height) // 2
        
        # ç²˜è´´å›¾ç‰‡
        grid.paste(img_resized, (x, y))
        
        # ç”»æ ‡ç­¾
        label_x = col * cell_size + cell_size // 2
        label_y = row * cell_size + 5
        draw.text((label_x, label_y), label, fill=(0, 0, 0), anchor="mt")
    
    return grid


def create_comparison_image(target_img: Image.Image, candidates: list, max_candidates: int = 16) -> tuple:
    """
    åˆ›å»ºå¯¹æ¯”å›¾ï¼šå·¦è¾¹æ˜¯å¾…è¯†åˆ«å›¾ï¼Œå³è¾¹æ˜¯å€™é€‰åº“ç½‘æ ¼
    
    Args:
        target_img: å¾…è¯†åˆ«çš„å›¾ç‰‡
        candidates: å€™é€‰æ ‡å¿—åˆ—è¡¨ [{"name": ..., "path": ...}, ...]
        max_candidates: æœ€å¤šæ˜¾ç¤ºå¤šå°‘ä¸ªå€™é€‰
    
    Returns:
        (åˆå¹¶å›¾, æ ‡ç­¾æ˜ å°„å­—å…¸)
    """
    # é™åˆ¶å€™é€‰æ•°é‡
    candidates = candidates[:max_candidates]
    
    # ç”Ÿæˆæ ‡ç­¾ A, B, C...
    labels = [chr(65 + i) for i in range(len(candidates))]  # A=65
    label_map = {labels[i]: candidates[i]["name"] for i in range(len(candidates))}
    
    # åŠ è½½å€™é€‰å›¾ç‰‡
    candidate_images = []
    for c in candidates:
        try:
            img = Image.open(c["path"]).convert("RGB")
            candidate_images.append(img)
        except:
            continue
    
    # åˆ›å»ºå€™é€‰ç½‘æ ¼
    grid = create_grid_image(candidate_images, labels, cols=4, cell_size=150)
    
    # è°ƒæ•´ç›®æ ‡å›¾å¤§å°
    target_resized = target_img.copy()
    target_resized.thumbnail((300, 300), Image.Resampling.LANCZOS)
    
    # åˆ›å»ºæœ€ç»ˆåˆå¹¶å›¾
    margin = 20
    total_width = target_resized.width + margin + grid.width + margin * 2
    total_height = max(target_resized.height, grid.height) + margin * 2
    
    merged = Image.new("RGB", (total_width, total_height), (240, 240, 240))
    
    # ç²˜è´´ç›®æ ‡å›¾ï¼ˆå·¦è¾¹ï¼‰
    merged.paste(target_resized, (margin, (total_height - target_resized.height) // 2))
    
    # ç²˜è´´å€™é€‰ç½‘æ ¼ï¼ˆå³è¾¹ï¼‰
    merged.paste(grid, (margin + target_resized.width + margin, (total_height - grid.height) // 2))
    
    # æ·»åŠ æ ‡é¢˜
    draw = ImageDraw.Draw(merged)
    draw.text((margin + target_resized.width // 2, 5), "å¾…è¯†åˆ«", fill=(0, 0, 0), anchor="mt")
    draw.text((margin + target_resized.width + margin + grid.width // 2, 5), "å€™é€‰åº“", fill=(0, 0, 0), anchor="mt")
    
    return merged, label_map


def classify_with_visual_fewshot(client: ZaiClient, target_img_path: str, bbox: list = None, category_hint: str = None) -> dict:
    """
    ä½¿ç”¨ Visual Few-Shot æ–¹å¼åˆ†ç±»äº¤é€šæ ‡å¿—
    
    Args:
        client: ZaiClient å®ä¾‹
        target_img_path: ç›®æ ‡å›¾ç‰‡è·¯å¾„
        bbox: æ ‡å¿—åŒºåŸŸ [x1, y1, x2, y2]ï¼Œå¦‚æœæä¾›åˆ™è£å‰ª
        category_hint: ç±»åˆ«æç¤ºï¼Œç”¨äºç¼©å°å€™é€‰èŒƒå›´
    
    Returns:
        åˆ†ç±»ç»“æœ
    """
    # åŠ è½½ç›®æ ‡å›¾ç‰‡
    img = Image.open(target_img_path).convert("RGB")
    
    # å¦‚æœæœ‰ bboxï¼Œè£å‰ª
    if bbox:
        padding = 10
        x1 = max(0, bbox[0] - padding)
        y1 = max(0, bbox[1] - padding)
        x2 = min(img.width, bbox[2] + padding)
        y2 = min(img.height, bbox[3] + padding)
        img = img.crop((x1, y1, x2, y2))
    
    # åŠ è½½æ ‡å‡†å›¾åº“
    signs_by_cat = load_standard_signs()
    
    # ç¡®å®šå€™é€‰èŒƒå›´
    if category_hint and category_hint in signs_by_cat:
        candidates = signs_by_cat[category_hint]
    else:
        # å¦‚æœæ²¡æœ‰æç¤ºï¼Œå…ˆåšç²—åˆ†ç±»
        # è¿™é‡Œç®€å•èµ·è§ï¼Œç”¨é™é€Ÿç±» + ç¦æ­¢ç±»ä½œä¸ºé»˜è®¤å€™é€‰
        candidates = signs_by_cat.get("speed_limit", []) + signs_by_cat.get("prohibition", [])[:10]
    
    if not candidates:
        # å¦‚æœæ²¡æœ‰å€™é€‰ï¼Œç”¨æ‰€æœ‰æ ‡å¿—
        for cat in signs_by_cat.values():
            candidates.extend(cat)
        candidates = candidates[:20]
    
    print(f"    ğŸ“š å€™é€‰åº“: {len(candidates)} å¼ æ ‡å‡†å›¾")
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    comparison_img, label_map = create_comparison_image(img, candidates)
    
    # ä¿å­˜å¯¹æ¯”å›¾ï¼ˆè°ƒè¯•ç”¨ï¼‰
    temp_path = "/tmp/visual_comparison.jpg"
    comparison_img.save(temp_path, "JPEG", quality=95)
    
    # ç¼–ç 
    with open(temp_path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode()
    
    # æ„å»º prompt
    label_list = "\n".join([f"  {label}: {name}" for label, name in sorted(label_map.items())])
    
    prompt = f"""è¿™æ˜¯ä¸€å¼ äº¤é€šæ ‡å¿—å¯¹æ¯”å›¾ã€‚

å·¦ä¾§æ˜¯ã€å¾…è¯†åˆ«å›¾ç‰‡ã€‘ï¼ˆä»é“è·¯è§†é¢‘ä¸­è£å‰ªï¼‰ã€‚
å³ä¾§æ˜¯ã€å€™é€‰åº“ã€‘ï¼Œæ¯å¼ æ ‡å‡†å›¾æ ‡æœ‰å­—æ¯ç¼–å·ï¼ˆA, B, C...ï¼‰ã€‚

å€™é€‰é¡¹ï¼š
{label_list}

ä»»åŠ¡ï¼š
1. ä»”ç»†è§‚å¯Ÿå·¦ä¾§å¾…è¯†åˆ«å›¾çš„é¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ã€æ•°å­—
2. ä¸å³ä¾§å€™é€‰åº“é€ä¸€å¯¹æ¯”
3. é€‰æ‹©æœ€åŒ¹é…çš„é‚£ä¸€å¼ 

è§„åˆ™ï¼š
- å¦‚æœæ˜¯é™é€Ÿæ ‡å¿—ï¼Œè¯·ä»”ç»†è¯†åˆ«æ•°å­—ï¼ˆ50 å’Œ 60 æ˜¯ä¸åŒçš„ï¼ï¼‰
- å¦‚æœéƒ½ä¸åƒï¼Œè¿”å› "NONE"

è¯·åªè¿”å›å­—æ¯ç¼–å·ï¼ˆå¦‚ Aã€Bã€Cï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

    try:
        response = client.chat.completions.create(
            model="glm-4.6v",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                    {"type": "text", "text": prompt}
                ]
            }],
            temperature=0.1  # ä½æ¸©åº¦å‡å°‘å¹»è§‰
        )
        
        choice = response.choices[0].message.content.strip().upper()
        
        # è§£æç»“æœ
        selected_name = None
        if choice in label_map:
            selected_name = label_map[choice]
        else:
            # å°è¯•æå–ç¬¬ä¸€ä¸ªå­—æ¯
            for char in choice:
                if char in label_map:
                    selected_name = label_map[char]
                    choice = char
                    break
        
        if selected_name:
            # ============================================================
            # äºŒé˜¶æ®µï¼šå¦‚æœæ˜¯é€šç”¨é™é€Ÿæ ‡å¿—ï¼Œè¿›ä¸€æ­¥è¯†åˆ«å…·ä½“æ•°å­—
            # ============================================================
            if "Speed_limit" in selected_name or "speed" in selected_name.lower():
                print("    ğŸ” äºŒé˜¶æ®µï¼šè¯†åˆ«é™é€Ÿæ•°å­—...")
                
                # é‡æ–°è¯»å–è£å‰ªå›¾
                with open(temp_path.replace("visual_comparison", "target_crop"), "rb") as f:
                    crop_data = base64.b64encode(f.read()).decode()
                
                # ç›´æ¥ç”¨è£å‰ªå›¾è¯†åˆ«æ•°å­—
                img_crop = Image.open(target_img_path).convert("RGB")
                if bbox:
                    padding = 10
                    x1 = max(0, bbox[0] - padding)
                    y1 = max(0, bbox[1] - padding)
                    x2 = min(img_crop.width, bbox[2] + padding)
                    y2 = min(img_crop.height, bbox[3] + padding)
                    img_crop = img_crop.crop((x1, y1, x2, y2))
                
                crop_temp = "/tmp/target_crop.jpg"
                img_crop.save(crop_temp, "JPEG")
                
                with open(crop_temp, "rb") as f:
                    crop_data = base64.b64encode(f.read()).decode()
                
                number_response = client.chat.completions.create(
                    model="glm-4.6v",
                    messages=[{
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{crop_data}"}},
                            {"type": "text", "text": "è¯·è¯†åˆ«è¿™ä¸ªé™é€Ÿæ ‡å¿—ä¸Šæ˜¾ç¤ºçš„å…·ä½“æ•°å­—ã€‚åªè¿”å›æ•°å­—ï¼Œå¦‚ 20ã€50ã€70ã€100ã€‚"}
                        ]
                    }],
                    temperature=0.1
                )
                
                number_text = number_response.choices[0].message.content.strip()
                
                import re
                numbers = re.findall(r'\d+', number_text)
                if numbers:
                    speed_value = numbers[0]
                    refined_label = f"Speed_limit_{speed_value}_km_h"
                    print(f"    â†’ è¯†åˆ«åˆ°æ•°å­—: {speed_value}")
                    return {
                        "success": True,
                        "choice": choice,
                        "label": refined_label,
                        "base_label": selected_name,
                        "speed_value": speed_value,
                        "candidates_count": len(candidates),
                        "comparison_image": temp_path
                    }
            
            return {
                "success": True,
                "choice": choice,
                "label": selected_name,
                "candidates_count": len(candidates),
                "comparison_image": temp_path
            }
        
        elif choice == "NONE":
            return {
                "success": False,
                "choice": "NONE",
                "label": "traffic_sign_unknown",
                "candidates_count": len(candidates)
            }
        else:
            return {
                "success": False,
                "choice": choice,
                "label": "traffic_sign",
                "raw_response": choice
            }
    
    except Exception as e:
        print(f"    âš ï¸ Visual Few-Shot å¤±è´¥: {e}")
        return {
            "success": False,
            "label": "traffic_sign",
            "error": str(e)
        }


def demo_visual_fewshot(image_path: str, bbox: list = None):
    """æ¼”ç¤º Visual Few-Shot åˆ†ç±»"""
    print("=" * 60)
    print("ğŸ” Visual Few-Shot äº¤é€šæ ‡å¿—åˆ†ç±»")
    print("=" * 60)
    
    api_key = os.getenv("ZAI_API_KEY")
    if not api_key:
        print("âŒ è¯·è®¾ç½® ZAI_API_KEY")
        return
    
    client = ZaiClient(api_key=api_key)
    
    print(f"\nğŸ“· ç›®æ ‡å›¾ç‰‡: {image_path}")
    if bbox:
        print(f"ğŸ“¦ è£å‰ªåŒºåŸŸ: {bbox}")
    
    print("\nâ³ åˆ›å»ºå¯¹æ¯”å›¾å¹¶è°ƒç”¨ GLM-4.6V...")
    
    result = classify_with_visual_fewshot(client, image_path, bbox, category_hint="speed_limit")
    
    print("\n" + "-" * 40)
    print("ğŸ“Š åˆ†ç±»ç»“æœ:")
    print(f"   é€‰æ‹©: {result.get('choice', 'N/A')}")
    print(f"   æ ‡ç­¾: {result['label']}")
    print(f"   å€™é€‰æ•°: {result.get('candidates_count', 'N/A')}")
    
    if result.get("comparison_image"):
        print(f"   å¯¹æ¯”å›¾: {result['comparison_image']}")
    
    print("=" * 60)
    
    return result


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Visual Few-Shot äº¤é€šæ ‡å¿—åˆ†ç±»")
    parser.add_argument("--test", type=str, help="æµ‹è¯•å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--bbox", type=str, help="è£å‰ªåŒºåŸŸ x1,y1,x2,y2")
    parser.add_argument("--category", type=str, default="speed_limit", help="ç±»åˆ«æç¤º")
    args = parser.parse_args()
    
    if args.test:
        bbox = None
        if args.bbox:
            bbox = [int(x) for x in args.bbox.split(",")]
        
        demo_visual_fewshot(args.test, bbox)
    else:
        # é»˜è®¤æµ‹è¯•
        demo_visual_fewshot(
            "test_images/extracted_frames/D1_frame_0006.jpg",
            bbox=[733, 270, 776, 300]  # å·²çŸ¥çš„é™é€Ÿæ ‡å¿—ä½ç½®
        )


if __name__ == "__main__":
    main()
