#!/usr/bin/env python3
"""
RAG æµç¨‹å¯è§†åŒ–æ¼”ç¤º

ç›´è§‚å±•ç¤º GLM-4.6V + RAG äº¤é€šæ ‡å¿—åˆ†ç±»çš„å®Œæ•´æµç¨‹

ç”¨æ³•:
    python3 demo_rag_flow.py --image D1_frame_0006.jpg
    python3 demo_rag_flow.py --prefix D1 --limit 5
"""

import os
import json
import base64
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from zai import ZaiClient

# ============================================================================
# åŠ¨æ€åŠ è½½ 188 ä¸ªé¦™æ¸¯é“è·¯æ ‡å¿—å€™é€‰åº“
# ============================================================================

SIGNS_DIR = Path("examples/signs/highres/png2560px")

def load_sign_candidates():
    """ä»æ ‡å¿—å›¾ç‰‡ç›®å½•åŠ¨æ€åŠ è½½æ‰€æœ‰æ ‡å¿—åç§°"""
    if not SIGNS_DIR.exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ ‡å¿—ç›®å½•: {SIGNS_DIR}")
        return []
    
    candidates = []
    for f in sorted(SIGNS_DIR.glob("*.png")):
        label = f.stem  # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
        candidates.append(label)
    
    return candidates

ALL_CANDIDATES = load_sign_candidates()


def print_box(title: str, content: list, width: int = 60):
    """æ‰“å°ç¾è§‚çš„ä¿¡æ¯æ¡†"""
    print("â”Œ" + "â”€" * (width - 2) + "â”")
    print(f"â”‚ {title:^{width - 4}} â”‚")
    print("â”œ" + "â”€" * (width - 2) + "â”¤")
    for line in content:
        if len(line) > width - 4:
            line = line[:width - 7] + "..."
        print(f"â”‚ {line:<{width - 4}} â”‚")
    print("â””" + "â”€" * (width - 2) + "â”˜")


def step_indicator(step: int, total: int, title: str):
    """æ­¥éª¤æŒ‡ç¤ºå™¨"""
    bar = "â–ˆ" * step + "â–‘" * (total - step)
    print(f"\n{'='*60}")
    print(f"  [{bar}] Step {step}/{total}: {title}")
    print(f"{'='*60}")


def detect_with_details(client: ZaiClient, image_path: str) -> list:
    """æ£€æµ‹å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯"""
    with open(image_path, 'rb') as f:
        img_data = base64.b64encode(f.read()).decode()
    
    img = Image.open(image_path)
    width, height = img.size
    
    prompt = """è¯·æ£€æµ‹å›¾ç‰‡ä¸­çš„äº¤é€šæ ‡å¿—å’Œè½¦è¾†ï¼Œè¿”å›JSONæ ¼å¼ã€‚

è½¦è¾†ï¼šcar, truck, bus, van, taxi, motorcycle
äº¤é€šæ ‡å¿—ï¼šç»Ÿä¸€ç”¨ traffic_sign æ ‡æ³¨

æ ¼å¼ï¼š[{"label": "car", "bbox_2d": [x1,y1,x2,y2]}]

åªè¿”å›JSONæ•°ç»„ã€‚"""

    response = client.chat.completions.create(
        model="glm-4.6v",
        messages=[{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                {"type": "text", "text": prompt}
            ]
        }]
    )
    
    result = response.choices[0].message.content.strip()
    
    try:
        if "[" in result:
            json_str = result[result.find("["):result.rfind("]")+1]
            detections = json.loads(json_str)
            
            processed = []
            for det in detections:
                if "label" not in det or "bbox_2d" not in det:
                    continue
                bbox = det["bbox_2d"]
                processed.append({
                    "label": det["label"],
                    "bbox": [
                        int(bbox[0] / 1000 * width),
                        int(bbox[1] / 1000 * height),
                        int(bbox[2] / 1000 * width),
                        int(bbox[3] / 1000 * height)
                    ]
                })
            return processed
    except:
        pass
    return []


def rag_classify_sign(client: ZaiClient, image_path: str, bbox: list) -> dict:
    """RAG åˆ†ç±»å•ä¸ªæ ‡å¿—ï¼Œè¿”å›è¯¦ç»†è¿‡ç¨‹"""
    img = Image.open(image_path)
    
    # æ‰©å¤§è£å‰ªåŒºåŸŸ
    x1, y1, x2, y2 = bbox
    padding = 10
    x1 = max(0, x1 - padding)
    y1 = max(0, y1 - padding)
    x2 = min(img.width, x2 + padding)
    y2 = min(img.height, y2 + padding)
    
    # è£å‰ª
    sign_crop = img.crop((x1, y1, x2, y2))
    
    # ä¿å­˜è£å‰ªå›¾
    temp_path = "/tmp/demo_sign_crop.jpg"
    sign_crop.save(temp_path, "JPEG")
    
    with open(temp_path, "rb") as f:
        crop_data = base64.b64encode(f.read()).decode()
    
    # æ„å»ºå€™é€‰åˆ—è¡¨
    candidate_list = "\n".join([f"{i+1}. {c}" for i, c in enumerate(ALL_CANDIDATES)])
    
    prompt = f"""è¯·ä»”ç»†è§‚å¯Ÿè¿™ä¸ªäº¤é€šæ ‡å¿—ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ï¼š

{candidate_list}

è§„åˆ™ï¼š
1. è§‚å¯Ÿé¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ã€æ•°å­—
2. å¦‚æœæ˜¯é™é€Ÿæ ‡å¿—ï¼Œè¯†åˆ«å…·ä½“æ•°å­—
3. å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›æ•°å­— 0

åªè¿”å›é€‰é¡¹ç¼–å·ï¼ˆ1-{len(ALL_CANDIDATES)}ï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

    response = client.chat.completions.create(
        model="glm-4.6v",
        messages=[{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{crop_data}"}},
                {"type": "text", "text": prompt}
            ]
        }]
    )
    
    choice = response.choices[0].message.content.strip()
    
    # è§£æç»“æœ
    import re
    numbers = re.findall(r'\d+', choice)
    selected_idx = -1
    selected_label = "unknown"
    
    if numbers:
        idx = int(numbers[0]) - 1
        if 0 <= idx < len(ALL_CANDIDATES):
            selected_idx = idx
            selected_label = ALL_CANDIDATES[idx]
    
    return {
        "crop_size": sign_crop.size,
        "crop_path": temp_path,
        "candidates_count": len(ALL_CANDIDATES),
        "raw_response": choice,
        "selected_index": selected_idx,
        "selected_label": selected_label
    }


def visualize_result(image_path: str, detections: list, rag_results: dict, output_path: str):
    """ç”Ÿæˆå¯è§†åŒ–ç»“æœå›¾"""
    img = Image.open(image_path)
    draw = ImageDraw.Draw(img)
    
    colors = {
        "vehicle": (0, 255, 0),
        "traffic_sign": (255, 100, 0),
        "rag_refined": (0, 100, 255)
    }
    
    for i, det in enumerate(detections):
        bbox = det["bbox"]
        label = det["label"]
        
        # åˆ¤æ–­é¢œè‰²
        if "sign" in label.lower():
            # å¦‚æœæœ‰ RAG ç»“æœï¼Œä½¿ç”¨ç²¾æ’åçš„æ ‡ç­¾
            if i in rag_results:
                label = rag_results[i]["selected_label"]
                color = colors["rag_refined"]
            else:
                color = colors["traffic_sign"]
        else:
            color = colors["vehicle"]
        
        # ç”»æ¡†
        draw.rectangle(bbox, outline=color, width=3)
        
        # ç”»æ ‡ç­¾
        text_bbox = draw.textbbox((bbox[0], bbox[1] - 20), label)
        draw.rectangle([text_bbox[0] - 2, text_bbox[1] - 2, text_bbox[2] + 2, text_bbox[3] + 2], fill=color)
        draw.text((bbox[0], bbox[1] - 20), label, fill=(255, 255, 255))
    
    img.save(output_path)
    return output_path


def demo_single_image(client: ZaiClient, image_path: str):
    """æ¼”ç¤ºå•å¼ å›¾ç‰‡çš„å®Œæ•´ RAG æµç¨‹"""
    
    print("\n" + "ğŸ”·" * 30)
    print(f"  ğŸ“· RAG æµç¨‹æ¼”ç¤º: {Path(image_path).name}")
    print("ğŸ”·" * 30)
    
    # Step 1: åŠ è½½å›¾ç‰‡
    step_indicator(1, 4, "ğŸ“ æ•°æ®å‡†å¤‡")
    img = Image.open(image_path)
    print_box("å›¾ç‰‡ä¿¡æ¯", [
        f"è·¯å¾„: {image_path}",
        f"å°ºå¯¸: {img.width} x {img.height}",
        f"æ ¼å¼: {img.format}"
    ])
    
    # Step 2: åŸºç¡€æ£€æµ‹
    step_indicator(2, 4, "ğŸ¤– æ¨¡å‹æ¨ç†ï¼ˆåŸºç¡€æ£€æµ‹ï¼‰")
    print("\n  â³ è°ƒç”¨ GLM-4.6V è¿›è¡Œç›®æ ‡æ£€æµ‹...")
    detections = detect_with_details(client, image_path)
    
    detection_info = []
    sign_indices = []
    for i, det in enumerate(detections):
        info = f"{i+1}. {det['label']:15} at {det['bbox']}"
        detection_info.append(info)
        if "sign" in det["label"].lower():
            sign_indices.append(i)
    
    if not detection_info:
        detection_info = ["(æœªæ£€æµ‹åˆ°ç›®æ ‡)"]
    
    print_box("æ£€æµ‹ç»“æœ", detection_info)
    
    # Step 3: RAG ç²¾æ’
    step_indicator(3, 4, "ğŸ” RAG ç²¾æ’ï¼ˆäº¤é€šæ ‡å¿—ç»†åˆ†ï¼‰")
    
    rag_results = {}
    
    if not sign_indices:
        print("\n  â„¹ï¸  æœªæ£€æµ‹åˆ°äº¤é€šæ ‡å¿—ï¼Œè·³è¿‡ RAG ç²¾æ’")
    else:
        print(f"\n  ğŸ“‹ å‘ç° {len(sign_indices)} ä¸ªäº¤é€šæ ‡å¿—ï¼Œå¼€å§‹ RAG ç²¾æ’...")
        print(f"  ğŸ“š å€™é€‰åº“: {len(ALL_CANDIDATES)} ç§æ ‡å‡†æ ‡å¿—\n")
        
        for idx in sign_indices:
            det = detections[idx]
            print(f"  â”Œâ”€ å¤„ç†æ ‡å¿— #{idx + 1}")
            print(f"  â”‚  ä½ç½®: {det['bbox']}")
            print(f"  â”‚  â³ è£å‰ªåŒºåŸŸ â†’ CLIP ç¼–ç  â†’ å‘é‡æ£€ç´¢...")
            
            # RAG åˆ†ç±»
            result = rag_classify_sign(client, image_path, det["bbox"])
            rag_results[idx] = result
            
            print(f"  â”‚  ğŸ“¤ GLM-4.6V ä» {result['candidates_count']} ä¸ªå€™é€‰ä¸­é€‰æ‹©...")
            print(f"  â”‚  âœ… ç»“æœ: {result['selected_label']}")
            print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
    
    # Step 4: ç»“æœå¯¼å‡º
    step_indicator(4, 4, "ğŸ“¦ ç»“æœå¯¼å‡º")
    
    # ç”Ÿæˆå¯è§†åŒ–
    output_dir = Path("output/rag_demo")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"{Path(image_path).stem}_rag_result.jpg"
    
    visualize_result(image_path, detections, rag_results, str(output_path))
    
    # æ±‡æ€»
    final_labels = []
    for i, det in enumerate(detections):
        if i in rag_results:
            label = f"{rag_results[i]['selected_label']} (RAGç²¾æ’)"
        else:
            label = det["label"]
        final_labels.append(label)
    
    print_box("æœ€ç»ˆæ ‡æ³¨ç»“æœ", final_labels if final_labels else ["(æ— ç›®æ ‡)"])
    print(f"\n  ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æµç¨‹å›¾
    print("\n" + "â”€" * 60)
    print("  ğŸ“Š RAG æµç¨‹å›é¡¾:")
    print("â”€" * 60)
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  åŸå§‹å›¾ç‰‡   â”‚ â”€â”€â–¶ â”‚ GLM-4.6V   â”‚ â”€â”€â–¶ â”‚ æ£€æµ‹åˆ°     â”‚
    â”‚            â”‚     â”‚ åŸºç¡€æ£€æµ‹    â”‚     â”‚ traffic_   â”‚
    â”‚            â”‚     â”‚            â”‚     â”‚ sign       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æœ€ç»ˆæ ‡ç­¾   â”‚ â—€â”€â”€ â”‚ GLM-4.6V   â”‚ â—€â”€â”€ â”‚ è£å‰ªæ ‡å¿—   â”‚
    â”‚ speed_     â”‚     â”‚ ä»å€™é€‰ä¸­    â”‚     â”‚ åŒºåŸŸ       â”‚
    â”‚ limit_70   â”‚     â”‚ ç²¾æ’é€‰æ‹©    â”‚     â”‚            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    return detections, rag_results


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="RAG æµç¨‹å¯è§†åŒ–æ¼”ç¤º")
    parser.add_argument("--image", type=str, help="å•å¼ å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--prefix", type=str, help="å›¾ç‰‡å‰ç¼€ (å¦‚ D1)")
    parser.add_argument("--limit", type=int, default=3, help="å¤„ç†æ•°é‡")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    api_key = os.getenv("ZAI_API_KEY")
    if not api_key:
        print("âŒ è¯·è®¾ç½® ZAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    client = ZaiClient(api_key=api_key)
    
    if args.image:
        # å•å¼ å›¾ç‰‡
        demo_single_image(client, args.image)
    
    elif args.prefix:
        # æ‰¹é‡å¤„ç†
        images_dir = Path("test_images/extracted_frames")
        image_files = sorted(images_dir.glob(f"{args.prefix}_*.jpg"))[:args.limit]
        
        print(f"\nğŸš€ æ‰¹é‡æ¼”ç¤º: {len(image_files)} å¼ å›¾ç‰‡\n")
        
        for img_path in image_files:
            demo_single_image(client, str(img_path))
            print("\n" + "â•" * 60 + "\n")
    
    else:
        # é»˜è®¤æ¼”ç¤º
        demo_image = "test_images/extracted_frames/D1_frame_0006.jpg"
        if Path(demo_image).exists():
            demo_single_image(client, demo_image)
        else:
            parser.print_help()


if __name__ == "__main__":
    main()
