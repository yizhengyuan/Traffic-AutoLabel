"""
è§†é¢‘å¤„ç†æ¨¡å—

æä¾›è§†é¢‘æŠ½å¸§ã€æ‰“åŒ…ç­‰åŠŸèƒ½ã€‚
"""

import subprocess
import shutil
import json
from pathlib import Path
from typing import Optional, Callable
from datetime import datetime
from collections import defaultdict


class VideoProcessor:
    """è§†é¢‘å¤„ç†å™¨"""
    
    # é»˜è®¤è§†é¢‘ç›®å½•
    DEFAULT_VIDEO_DIR = Path("traffic_sign_data/videos/raw_videos")
    
    def __init__(self, video_dir: Optional[str] = None):
        self.video_dir = Path(video_dir) if video_dir else self.DEFAULT_VIDEO_DIR
    
    def list_videos(self) -> list:
        """åˆ—å‡ºå¯ç”¨çš„è§†é¢‘æ–‡ä»¶"""
        videos = []
        if self.video_dir.exists():
            for ext in ['*.mp4', '*.MP4', '*.avi', '*.mov']:
                videos.extend(self.video_dir.glob(ext))
        return sorted([v.stem for v in videos])
    
    def get_video_path(self, video_name: str) -> Optional[Path]:
        """è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„"""
        for ext in ['.mp4', '.MP4', '.avi', '.mov']:
            path = self.video_dir / f"{video_name}{ext}"
            if path.exists():
                return path
        return None
    
    def extract_frames(
        self,
        video_name: str,
        output_dir: Path,
        fps: int = 3,
        output_prefix: str = None,
        on_progress: Callable[[float], None] = None
    ) -> tuple:
        """
        ä»è§†é¢‘æŠ½å¸§
        
        Args:
            video_name: è§†é¢‘åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
            output_dir: è¾“å‡ºç›®å½•
            fps: æŠ½å¸§ç‡
            output_prefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆé»˜è®¤ä¸è§†é¢‘åŒåï¼‰
            on_progress: è¿›åº¦å›è°ƒ (0.0 ~ 1.0)
            
        Returns:
            (frames_dir, frame_count) æˆ– (None, 0) å¤±è´¥æ—¶
        """
        video_path = self.get_video_path(video_name)
        if not video_path:
            return None, 0
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¸…ç©ºæ—§å¸§
        for old_frame in output_dir.glob("*.jpg"):
            old_frame.unlink()
        
        prefix = output_prefix or video_name
        output_pattern = str(output_dir / f"{prefix}_%06d.jpg")
        
        # è·å–è§†é¢‘æ—¶é•¿ï¼ˆç”¨äºè®¡ç®—è¿›åº¦ï¼‰
        duration = self._get_video_duration(video_path)
        
        cmd = [
            "ffmpeg", "-i", str(video_path),
            "-vf", f"fps={fps}",
            "-q:v", "2",
            output_pattern,
            "-y",
            "-progress", "pipe:1"
        ]
        
        try:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # è§£æè¿›åº¦
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line.startswith("out_time_ms="):
                    try:
                        current_ms = int(line.split("=")[1])
                        if duration > 0 and on_progress:
                            progress = min(current_ms / (duration * 1000000), 1.0)
                            on_progress(progress)
                    except:
                        pass
            
            process.wait()
            
            if on_progress:
                on_progress(1.0)
            
            frame_count = len(list(output_dir.glob("*.jpg")))
            return output_dir, frame_count
            
        except Exception as e:
            print(f"ffmpeg error: {e}")
            return None, 0
    
    def _get_video_duration(self, video_path: Path) -> float:
        """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            cmd = [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(video_path)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            return float(result.stdout.strip())
        except:
            return 0
    
    def create_dataset(
        self,
        video_name: str,
        output_name: str,
        frames_dir: Path,
        annotations_dir: Path,
        visualized_dir: Optional[Path],
        fps: int = 3,
        use_rag: bool = False,
        on_progress: Callable[[float], None] = None
    ) -> Optional[Path]:
        """
        åˆ›å»ºæ•°æ®é›†æ–‡ä»¶å¤¹
        
        Args:
            video_name: åŸå§‹è§†é¢‘åç§°
            output_name: è¾“å‡ºæ•°æ®é›†åç§°
            frames_dir: å¸§ç›®å½•
            annotations_dir: æ ‡æ³¨ç›®å½•
            visualized_dir: å¯è§†åŒ–ç›®å½•
            fps: æŠ½å¸§ç‡
            use_rag: æ˜¯å¦ä½¿ç”¨ RAG
            on_progress: è¿›åº¦å›è°ƒ
            
        Returns:
            æ•°æ®é›†ç›®å½•è·¯å¾„
        """
        output_base = Path("dataset_output")
        output_base.mkdir(parents=True, exist_ok=True)
        dataset_dir = output_base / f"{output_name}_dataset"
        
        # åˆ›å»ºç›®å½•ç»“æ„
        (dataset_dir / "video").mkdir(parents=True, exist_ok=True)
        (dataset_dir / "frames").mkdir(parents=True, exist_ok=True)
        (dataset_dir / "annotations").mkdir(parents=True, exist_ok=True)
        (dataset_dir / "visualized").mkdir(parents=True, exist_ok=True)
        
        total_steps = 5
        current_step = 0
        
        def update_progress():
            nonlocal current_step
            current_step += 1
            if on_progress:
                on_progress(current_step / total_steps)
        
        # 1. å¤åˆ¶è§†é¢‘
        video_path = self.get_video_path(video_name)
        if video_path and video_path.exists():
            shutil.copy(video_path, dataset_dir / "video" / video_path.name)
        update_progress()
        
        # 2. å¤åˆ¶å¸§
        frames_dir = Path(frames_dir)
        for frame in frames_dir.glob("*.jpg"):
            shutil.copy(frame, dataset_dir / "frames" / frame.name)
        update_progress()
        
        # 3. å¤åˆ¶æ ‡æ³¨
        annotations_dir = Path(annotations_dir)
        for ann in annotations_dir.glob("*.json"):
            shutil.copy(ann, dataset_dir / "annotations" / ann.name)
        update_progress()
        
        # 4. å¤åˆ¶å¯è§†åŒ–
        if visualized_dir:
            visualized_dir = Path(visualized_dir)
            if visualized_dir.exists():
                for vis in visualized_dir.glob("*.jpg"):
                    shutil.copy(vis, dataset_dir / "visualized" / vis.name)
        update_progress()
        
        # 5. ç”Ÿæˆæ€»ç»“æ–‡æ¡£
        frame_count = len(list(frames_dir.glob("*.jpg")))
        stats = self._generate_summary(annotations_dir, output_name, frame_count, fps)
        summary_md = self._create_summary_markdown(stats, output_name, fps, use_rag)
        
        with open(dataset_dir / "SUMMARY.md", "w", encoding="utf-8") as f:
            f.write(summary_md)
        
        # ä¿å­˜ JSON ç»Ÿè®¡
        stats_json = {
            "video_name": video_name,
            "output_name": output_name,
            "total_frames": stats["total_frames"],
            "annotated_frames": stats["annotated_frames"],
            "total_objects": stats["total_objects"],
            "categories": dict(stats["categories"]),
            "fps": fps,
            "use_rag": use_rag,
            "created_at": datetime.now().isoformat()
        }
        with open(dataset_dir / "stats.json", "w", encoding="utf-8") as f:
            json.dump(stats_json, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºå‹ç¼©åŒ…
        zip_path = output_base / f"{output_name}_dataset.zip"
        shutil.make_archive(str(dataset_dir), 'zip', str(output_base), f"{output_name}_dataset")
        
        update_progress()
        
        return dataset_dir
    
    def _generate_summary(self, annotations_dir: Path, name: str, frame_count: int, fps: int) -> dict:
        """åˆ†ææ ‡æ³¨æ•°æ®"""
        stats = {
            "total_frames": frame_count,
            "annotated_frames": 0,
            "total_objects": 0,
            "categories": defaultdict(int),
            "subcategories": defaultdict(int),
        }
        
        for json_path in annotations_dir.glob("*.json"):
            try:
                with open(json_path, encoding="utf-8") as f:
                    data = json.load(f)
                
                shapes = data.get("shapes", [])
                if shapes:
                    stats["annotated_frames"] += 1
                
                for shape in shapes:
                    stats["total_objects"] += 1
                    category = shape.get("flags", {}).get("category", "unknown")
                    stats["categories"][category] += 1
                    label = shape.get("label", "")
                    if label:
                        stats["subcategories"][label] += 1
            except:
                pass
        
        return stats
    
    def _create_summary_markdown(self, stats: dict, name: str, fps: int, use_rag: bool) -> str:
        """ç”Ÿæˆ Markdown æ€»ç»“"""
        lines = []
        lines.append(f"# ğŸ“Š æ•°æ®æ ‡æ³¨æ€»ç»“ - {name}")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**æŠ½å¸§ç‡**: {fps} FPS")
        lines.append(f"**RAGå¢å¼º**: {'âœ… å¯ç”¨' if use_rag else 'âŒ æœªå¯ç”¨'}")
        lines.append("")
        
        lines.append("## ğŸ“ˆ æ¦‚è§ˆç»Ÿè®¡")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        lines.append("|------|------|")
        lines.append(f"| æ€»å¸§æ•° | {stats['total_frames']} |")
        lines.append(f"| æœ‰æ ‡æ³¨çš„å¸§ | {stats['annotated_frames']} |")
        lines.append(f"| æ€»æ£€æµ‹å¯¹è±¡ | {stats['total_objects']} |")
        lines.append("")
        
        lines.append("## ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ")
        lines.append("")
        lines.append("| ç±»åˆ« | æ•°é‡ | å æ¯” |")
        lines.append("|------|------|------|")
        total = stats['total_objects'] or 1
        for cat, count in sorted(stats['categories'].items(), key=lambda x: -x[1]):
            pct = count / total * 100
            lines.append(f"| {cat} | {count} | {pct:.1f}% |")
        lines.append("")
        
        lines.append("---")
        lines.append("*ç”± GLM Labeling Dashboard è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(lines)

