#!/usr/bin/env python3
"""
ğŸš€ å¼‚æ­¥ç‰ˆæœ¬ - è§†é¢‘åˆ°æ•°æ®é›†æµæ°´çº¿

ä½¿ç”¨ asyncio + httpx å®ç°çœŸæ­£çš„å¹¶å‘ API è¯·æ±‚ï¼Œé€Ÿåº¦æ›´å¿«ã€‚

ç”¨æ³•:
    python3 scripts/video_to_dataset_async.py --video D4.1 --workers 15
"""

import os
import sys
import json
import argparse
import subprocess
import time
import asyncio
import base64
from pathlib import Path
from typing import List, Dict, Any, Optional

import httpx
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from glm_labeling.utils.labels import get_category, normalize_vehicle_label
from glm_labeling.utils.json_utils import parse_llm_json


# ============================================================================
# é…ç½®
# ============================================================================

API_BASE_URL = "https://api.z.ai/api/paas/v4"
MODEL_NAME = "glm-4.6v"
COORD_BASE = 1000  # GLM è¾“å‡ºåæ ‡åŸºæ•°

VIDEO_DIR = Path("traffic_sign_data/videos/clips")  # é»˜è®¤æŸ¥æ‰¾åˆ‡åˆ†åçš„ç‰‡æ®µ
TEMP_FRAMES_DIR = Path("temp_frames")
OUTPUT_BASE = Path("output")

# 188 ç§äº¤é€šæ ‡å¿—å€™é€‰åº“
SIGNS_DIR = Path("traffic_sign_data/images/signs/highres/png2560px")

def load_sign_candidates():
    """ä»æ ‡å¿—å›¾ç‰‡ç›®å½•åŠ¨æ€åŠ è½½æ‰€æœ‰æ ‡å¿—åç§°ï¼ˆ188ç§ï¼‰"""
    if not SIGNS_DIR.exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ ‡å¿—ç›®å½•: {SIGNS_DIR}")
        return []
    return [f.stem for f in sorted(SIGNS_DIR.glob("*.png"))]

ALL_SIGN_CANDIDATES = load_sign_candidates()

COLORS = {
    'pedestrian': (255, 0, 0),
    'vehicle': (0, 255, 0),
    'traffic_sign': (0, 100, 255),
    'construction': (255, 165, 0),
}

DETECTION_PROMPT = """è¯·æ£€æµ‹å›¾ç‰‡ä¸­çš„ä»¥ä¸‹4ç±»ç‰©ä½“ï¼Œè¿”å›JSONæ ¼å¼ã€‚

## é‡è¦æ’é™¤è§„åˆ™ï¼š
â›” ä¸è¦æ ‡æ³¨ç¬¬ä¸€äººç§°è§†è§’ä¸‹è‡ªå·±éª‘çš„è½¦ï¼ˆæ‘©æ‰˜è½¦/ç”µåŠ¨è½¦/è‡ªè¡Œè½¦çš„è½¦æŠŠã€ä»ªè¡¨ç›˜ã€æ‰‹è‡‚ç­‰ï¼‰ï¼

## æ£€æµ‹ç±»åˆ«ä¸ç»†ç²’åº¦è¦æ±‚ï¼š

### 1. è¡Œäººç±» (pedestrian) - 2ç§æ ‡ç­¾
- pedestrian: å•ä¸ªæˆ–å°‘é‡è¡Œäºº
- crowd: äººç¾¤ï¼ˆå¤šäººèšé›†ï¼‰

### 2. è½¦è¾†ç±» (vehicle) - 5ç§æ ‡ç­¾
ç»Ÿä¸€ä½¿ç”¨ vehicleï¼ŒåªåŒºåˆ†è¡Œé©¶çŠ¶æ€ï¼š

**ğŸš¨ çŠ¶æ€åˆ¤æ–­è§„åˆ™ï¼ˆæ ¸å¿ƒï¼šå…³æ³¨å°¾ç¯ï¼æŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**
1. **åˆ¹è½¦çŠ¶æ€**: å°¾ç¯æ˜æ˜¾å˜äº®ã€çº¢è‰²åˆ¹è½¦ç¯äº®èµ· â†’ `vehicle_braking`
2. **åŒé—ªçŠ¶æ€**: å·¦å³ä¸¤ä¾§è½¬å‘ç¯åŒæ—¶äº®èµ·/é—ªçƒ â†’ `vehicle_double_flash`
3. **å³è½¬çŠ¶æ€**: å³ä¾§è½¬å‘ç¯äº®ï¼ˆé»„è‰²/ç¥ç€è‰²ï¼‰æˆ–æ˜æ˜¾å³è½¬å¼¯ â†’ `vehicle_turning_right`
4. **å·¦è½¬çŠ¶æ€**: å·¦ä¾§è½¬å‘ç¯äº®ï¼ˆé»„è‰²/ç¥ç€è‰²ï¼‰æˆ–æ˜æ˜¾å·¦è½¬å¼¯ â†’ `vehicle_turning_left`
5. **æ­£å¸¸çŠ¶æ€**: ç›´è¡Œæˆ–æ— ç¯å…‰ä¿¡å· â†’ `vehicle`

âš ï¸ æ³¨æ„ï¼šä»…é“è·¯å¼¯æ›²ä½†è½¦è¾†æ­£å¸¸è¡Œé©¶ã€æ²¡æœ‰æ‰“ç¯ â†’ æ ‡ä¸º `vehicle`ï¼ˆç›´è¡Œï¼‰

### 3. äº¤é€šæ ‡å¿—ç±» (traffic_sign)
traffic_sign

### 4. æ–½å·¥æ ‡å¿—ç±» (construction)
traffic_cone, construction_barrier

## è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
[
  {"label": "vehicle_braking", "bbox_2d": [100, 200, 300, 400]},
  {"label": "vehicle_double_flash", "bbox_2d": [400, 300, 600, 500]},
  {"label": "traffic_sign", "bbox_2d": [50, 50, 80, 80]}
]

å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œè¿”å› []
åªè¿”å›JSONæ•°ç»„ï¼"""


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

import re
import uuid


def image_to_base64_url(image_path: str) -> str:
    """å°†å›¾ç‰‡è½¬ä¸º base64 data URL"""
    with open(image_path, "rb") as f:
        data = base64.b64encode(f.read()).decode("utf-8")
    
    ext = Path(image_path).suffix.lower()
    mime = {"jpg": "jpeg", "jpeg": "jpeg", "png": "png", "gif": "gif", "webp": "webp"}
    mime_type = mime.get(ext.lstrip("."), "jpeg")
    
    return f"data:image/{mime_type};base64,{data}"


def get_image_size(image_path: str) -> tuple:
    """è·å–å›¾ç‰‡å°ºå¯¸"""
    with Image.open(image_path) as img:
        return img.size  # (width, height)


def convert_coords(bbox: List[int], width: int, height: int) -> List[int]:
    """å°† GLM å½’ä¸€åŒ–åæ ‡ (0-1000) è½¬ä¸ºåƒç´ åæ ‡"""
    x1, y1, x2, y2 = bbox
    return [
        int(x1 * width / COORD_BASE),
        int(y1 * height / COORD_BASE),
        int(x2 * width / COORD_BASE),
        int(y2 * height / COORD_BASE)
    ]


def to_xanylabeling_format(detections: List[Dict], image_path: str) -> Dict:
    """è½¬æ¢ä¸º X-AnyLabeling æ ¼å¼"""
    width, height = get_image_size(image_path)
    
    shapes = []
    for det in detections:
        bbox = det["bbox"]
        shapes.append({
            "label": det["label"],
            "points": [[bbox[0], bbox[1]], [bbox[2], bbox[3]]],
            "shape_type": "rectangle",
            "flags": {"category": det["category"]}
        })
    
    return {
        "version": "0.4.0",
        "flags": {},
        "shapes": shapes,
        "imagePath": Path(image_path).name,
        "imageHeight": height,
        "imageWidth": width
    }


# ============================================================================
# å¼‚æ­¥ API è°ƒç”¨
# ============================================================================

class AsyncDetector:
    """å¼‚æ­¥ç›®æ ‡æ£€æµ‹å™¨"""
    
    def __init__(self, api_key: str, max_concurrent: int = 12, timeout: float = 45.0):
        self.api_key = api_key
        self.timeout = timeout
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.client: Optional[httpx.AsyncClient] = None
    
    async def __aenter__(self):
        self.client = httpx.AsyncClient(
            base_url=API_BASE_URL,
            timeout=httpx.Timeout(self.timeout, connect=10.0),
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            limits=httpx.Limits(max_connections=30, max_keepalive_connections=15)
        )
        return self
    
    async def __aexit__(self, *args):
        if self.client:
            await self.client.aclose()
    
    async def detect(self, image_path: str, retry: int = 3) -> tuple:
        """
        å¼‚æ­¥æ£€æµ‹å•å¼ å›¾ç‰‡
        
        Returns:
            (detections, error)
        """
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘
            return await self._detect_with_retry(image_path, retry)
    
    async def _detect_with_retry(self, image_path: str, max_retry: int) -> tuple:
        """å¸¦é‡è¯•çš„æ£€æµ‹"""
        image_name = Path(image_path).name
        last_error = None
        
        for attempt in range(max_retry):
            try:
                base64_url = image_to_base64_url(image_path)
                width, height = get_image_size(image_path)
                
                payload = {
                    "model": MODEL_NAME,
                    "messages": [{
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": base64_url}},
                            {"type": "text", "text": DETECTION_PROMPT}
                        ]
                    }]
                }
                
                response = await self.client.post("/chat/completions", json=payload)
                
                # å¤„ç† 429 é™æµ
                if response.status_code == 429:
                    retry_after = float(response.headers.get("Retry-After", 3))
                    await asyncio.sleep(retry_after * (attempt + 1))
                    continue
                
                response.raise_for_status()
                data = response.json()
                
                content = data["choices"][0]["message"]["content"]
                detections = parse_llm_json(content)
                
                if detections is None:
                    # JSON è§£æå¤±è´¥ï¼Œé‡è¯•
                    last_error = "JSON parse error"
                    await asyncio.sleep(1)
                    continue
                
                if not detections:
                    return [], None
                
                # åå¤„ç†
                processed = []
                for det in detections:
                    if "label" not in det or "bbox_2d" not in det:
                        continue
                    
                    bbox = convert_coords(det["bbox_2d"], width, height)
                    label = det["label"].lower().replace(" ", "_").replace("-", "_")
                    category = get_category(label)
                    
                    if category == "vehicle":
                        label = normalize_vehicle_label(label)
                    
                    processed.append({
                        "label": label,
                        "category": category,
                        "bbox": bbox
                    })
                
                return processed, None
                
            except httpx.TimeoutException:
                last_error = "Timeout"
                await asyncio.sleep(2 * (attempt + 1))
            except httpx.HTTPStatusError as e:
                last_error = f"HTTP {e.response.status_code}"
                if e.response.status_code == 429:
                    await asyncio.sleep(3 * (attempt + 1))
                else:
                    await asyncio.sleep(2)
        
        return [], last_error
    
    async def classify_sign_rag(self, image_path: str, bbox: list) -> str:
        """
        RAG äº¤é€šæ ‡å¿—ç²¾æ’ï¼ˆå¼‚æ­¥ç‰ˆï¼‰- æ”¯æŒ 188 ç§ç»†ç²’åº¦åˆ†ç±»
        
        Args:
            image_path: åŸå›¾è·¯å¾„
            bbox: äº¤é€šæ ‡å¿—çš„è¾¹ç•Œæ¡† [x1, y1, x2, y2]
        
        Returns:
            ç»†ç²’åº¦æ ‡ç­¾ï¼Œå¦‚ Speed_limit_70_km_h, No_stopping_at_any_time ç­‰
        """
        if not ALL_SIGN_CANDIDATES:
            return "traffic_sign"
        
        temp_path = None
        
        try:
            img = Image.open(image_path)
            padding = 10
            x1 = max(0, bbox[0] - padding)
            y1 = max(0, bbox[1] - padding)
            x2 = min(img.width, bbox[2] + padding)
            y2 = min(img.height, bbox[3] + padding)
            
            sign_crop = img.crop((x1, y1, x2, y2))
            unique_id = uuid.uuid4()
            temp_path = f"/tmp/sign_crop_{unique_id}.jpg"
            sign_crop.save(temp_path, "JPEG")
            
            with open(temp_path, "rb") as f:
                img_data = base64.b64encode(f.read()).decode()
            
            base64_url = f"data:image/jpeg;base64,{img_data}"
            
            # ================================================================
            # é˜¶æ®µ1ï¼šä» 188 ç§å€™é€‰ä¸­é€‰æ‹©æœ€åŒ¹é…çš„æ ‡å¿—
            # ================================================================
            candidate_list = "\n".join([f"{i+1}. {c}" for i, c in enumerate(ALL_SIGN_CANDIDATES)])
            
            select_prompt = f"""è¯·ä»”ç»†è§‚å¯Ÿè¿™ä¸ªäº¤é€šæ ‡å¿—ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ï¼š

{candidate_list}

è§„åˆ™ï¼š
1. è§‚å¯Ÿæ ‡å¿—çš„é¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ã€æ•°å­—
2. å¦‚æœæ˜¯é™é€Ÿæ ‡å¿—ï¼Œé€‰æ‹© "Speed_limit_(in_km_h)"
3. å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å› 0

è¯·åªè¿”å›é€‰é¡¹ç¼–å·ï¼ˆå¦‚ 1ã€2ã€3ï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
            
            payload = {
                "model": MODEL_NAME,
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": base64_url}},
                        {"type": "text", "text": select_prompt}
                    ]
                }],
                "temperature": 0.1
            }
            
            response = await self.client.post("/chat/completions", json=payload)
            response.raise_for_status()
            choice = response.json()["choices"][0]["message"]["content"].strip()
            
            # è§£æé€‰æ‹©
            base_label = "traffic_sign"
            numbers = re.findall(r'\d+', choice)
            if numbers:
                idx = int(numbers[0]) - 1
                if 0 <= idx < len(ALL_SIGN_CANDIDATES):
                    base_label = ALL_SIGN_CANDIDATES[idx]
            
            # ================================================================
            # é˜¶æ®µ2ï¼šå¯¹é€šç”¨æ ‡å¿—è¿›ä¸€æ­¥è¯†åˆ«å…·ä½“æ•°å­—
            # ================================================================
            generic_signs = {
                "Speed_limit_(in_km_h)": {
                    "question": "è¯·è¯†åˆ«è¿™ä¸ªé™é€Ÿæ ‡å¿—ä¸Šæ˜¾ç¤ºçš„å…·ä½“æ•°å­—ï¼ˆå¦‚ 20, 30, 50, 70, 100ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                    "format": "Speed_limit_{}_km_h"
                },
                "Variable_speed_limit_(in_km_h)": {
                    "question": "è¯·è¯†åˆ«è¿™ä¸ªå¯å˜é™é€Ÿæ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æ•°å­—ã€‚åªè¿”å›æ•°å­—ã€‚",
                    "format": "Variable_speed_limit_{}_km_h"
                },
                "Distance_as_shown_to_hazard": {
                    "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„è·ç¦»æ•°å­—ï¼ˆå•ä½ï¼šç±³ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                    "format": "Distance_{}_m_to_hazard"
                },
                "Maximum_height_as_shown_(in_metres)": {
                    "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æœ€å¤§é«˜åº¦é™åˆ¶ï¼ˆå•ä½ï¼šç±³ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                    "format": "Maximum_height_{}_m"
                },
                "Maximum_payload_as_shown_(in_tonnes)": {
                    "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æœ€å¤§è½½é‡é™åˆ¶ï¼ˆå•ä½ï¼šå¨ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                    "format": "Maximum_payload_{}_tonnes"
                }
            }
            
            if base_label in generic_signs:
                detail_info = generic_signs[base_label]
                
                payload["messages"][0]["content"][1]["text"] = detail_info["question"]
                
                response2 = await self.client.post("/chat/completions", json=payload)
                response2.raise_for_status()
                detail_text = response2.json()["choices"][0]["message"]["content"].strip()
                
                detail_numbers = re.findall(r'\d+', detail_text)
                if detail_numbers:
                    specific_value = detail_numbers[0]
                    return detail_info["format"].format(specific_value)
            
            return base_label
            
        except Exception as e:
            return "traffic_sign"
        
        finally:
            if temp_path and os.path.exists(temp_path):
                os.remove(temp_path)


# ============================================================================
# Step 1: æŠ½å¸§
# ============================================================================

def extract_frames(video_path: str, output_name: str, fps: int = 3) -> tuple:
    """ä»è§†é¢‘æŠ½å¸§
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_name: è¾“å‡ºåç§°ï¼ˆç”¨äºå‘½åå¸§å’Œç›®å½•ï¼‰
        fps: æŠ½å¸§ç‡
    """
    video_path = Path(video_path)
    
    if not video_path.exists():
        print(f"âŒ è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return None, 0
    
    frames_dir = TEMP_FRAMES_DIR / output_name
    frames_dir.mkdir(parents=True, exist_ok=True)
    
    # æ¸…ç©ºæ—§å¸§
    for old_frame in frames_dir.glob("*.jpg"):
        old_frame.unlink()
    
    print(f"\nğŸ“¹ Step 1: æŠ½å¸§ ({fps} FPS)")
    print(f"   è§†é¢‘: {video_path}")
    
    output_pattern = str(frames_dir / f"{output_name}_%06d.jpg")
    cmd = [
        "ffmpeg", "-i", str(video_path),
        "-vf", f"fps={fps}",
        "-q:v", "2",
        output_pattern,
        "-y"
    ]
    
    try:
        subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        frame_count = len(list(frames_dir.glob("*.jpg")))
        print(f"   âœ… æŠ½å– {frame_count} å¸§")
        return frames_dir, frame_count
    except Exception as e:
        print(f"   âŒ ffmpeg é”™è¯¯: {e}")
        return None, 0


# ============================================================================
# Step 2: å¼‚æ­¥æ ‡æ³¨
# ============================================================================

async def run_labeling_async(
    frames_dir: Path, 
    video_name: str, 
    workers: int,
    api_key: str,
    use_rag: bool = True
) -> Path:
    """å¼‚æ­¥è¿è¡Œæ ‡æ³¨"""
    rag_status = "âœ… å¯ç”¨" if use_rag else "âŒ ç¦ç”¨"
    print(f"\nğŸ·ï¸ Step 2: å¼‚æ­¥æ ‡æ³¨")
    print(f"   å¹¶å‘æ•°: {workers} | æ¨¡å¼: asyncio + httpx | RAG: {rag_status}")
    
    image_files = sorted(frames_dir.glob("*.jpg"))
    if not image_files:
        print("   âŒ æ²¡æœ‰æ‰¾åˆ°å¸§")
        return None
    
    output_dir = OUTPUT_BASE / f"{video_name.lower()}_annotations"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿‡æ»¤å·²å¤„ç†çš„ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    todo_files = []
    for img in image_files:
        json_path = output_dir / f"{img.stem}.json"
        if not json_path.exists():
            todo_files.append(img)
    
    skipped = len(image_files) - len(todo_files)
    if skipped > 0:
        print(f"   ğŸ“Œ æ–­ç‚¹ç»­ä¼ : è·³è¿‡ {skipped} å¼ å·²å¤„ç†")
    
    if not todo_files:
        print("   âœ… æ‰€æœ‰å¸§å·²å¤„ç†å®Œæˆ")
        return output_dir
    
    print(f"   ğŸ“ å¾…å¤„ç†: {len(todo_files)} å¸§")
    
    start_time = time.time()
    stats = {"pedestrian": 0, "vehicle": 0, "traffic_sign": 0, "construction": 0}
    success = 0
    errors = 0
    
    async with AsyncDetector(api_key, max_concurrent=workers) as detector:
        # åˆ›å»ºä»»åŠ¡å¹¶è®°å½•å¯¹åº”çš„æ–‡ä»¶
        tasks = {
            asyncio.create_task(
                detect_and_save(detector, str(img), output_dir, stats, use_rag=use_rag)
            ): img for img in todo_files
        }
        
        total = len(image_files)
        completed = 0
        
        # å®æ—¶è¾“å‡ºï¼šä»»åŠ¡å®Œæˆä¸€ä¸ªå°±è¾“å‡ºä¸€ä¸ª
        for coro in asyncio.as_completed(tasks.keys()):
            completed += 1
            idx = skipped + completed
            
            try:
                result = await coro
                
                if result[1]:  # error
                    print(f"  âš ï¸ [{idx}/{total}] {result[1]}", flush=True)
                    errors += 1
                else:
                    count = result[0]
                    emoji = "âœ…" if count > 0 else "âšª"
                    print(f"  {emoji} [{idx}/{total}] {count} objects", flush=True)
                    success += 1
                    
            except Exception as e:
                print(f"  âŒ [{idx}/{total}] {e}", flush=True)
                errors += 1
    
    elapsed = time.time() - start_time
    print(f"\n   ğŸ“Š ç»Ÿè®¡: {dict(stats)}")
    print(f"   â±ï¸ è€—æ—¶: {elapsed:.1f}s ({elapsed/len(todo_files):.2f}s/å¸§)")
    print(f"   âœ… æˆåŠŸ: {success} | âŒ é”™è¯¯: {errors}")
    
    return output_dir


async def detect_and_save(
    detector: AsyncDetector,
    image_path: str,
    output_dir: Path,
    stats: dict,
    use_rag: bool = True
) -> tuple:
    """æ£€æµ‹å¹¶ä¿å­˜ç»“æœ"""
    detections, error = await detector.detect(image_path)
    
    if error:
        return (0, error)
    
    # RAG ç»†ç²’åº¦åˆ†ç±»ï¼ˆäº¤é€šæ ‡å¿—ï¼‰
    if use_rag:
        for det in detections:
            if det.get("category") == "traffic_sign" and det.get("label") in ["traffic_sign", "sign"]:
                fine_label = await detector.classify_sign_rag(image_path, det["bbox"])
                det["label"] = fine_label
    
    # æ›´æ–°ç»Ÿè®¡
    for det in detections:
        cat = det.get("category", "unknown")
        if cat in stats:
            stats[cat] += 1
    
    # ä¿å­˜
    annotation = to_xanylabeling_format(detections, image_path)
    out_path = output_dir / f"{Path(image_path).stem}.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(annotation, f, ensure_ascii=False, indent=2)
    
    return (len(detections), None)


# ============================================================================
# Step 3: å¯è§†åŒ–
# ============================================================================

def generate_visualizations(frames_dir: Path, annotations_dir: Path, video_name: str) -> Path:
    """ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡"""
    from PIL import ImageDraw
    
    print(f"\nğŸ¨ Step 3: ç”Ÿæˆå¯è§†åŒ–")
    
    vis_dir = OUTPUT_BASE / f"{video_name.lower()}_visualized"
    vis_dir.mkdir(parents=True, exist_ok=True)
    
    count = 0
    for json_path in sorted(annotations_dir.glob("*.json")):
        frame_name = json_path.stem + ".jpg"
        frame_path = frames_dir / frame_name
        
        if not frame_path.exists():
            continue
        
        img = Image.open(frame_path)
        draw = ImageDraw.Draw(img)
        
        with open(json_path) as f:
            data = json.load(f)
        
        for shape in data.get("shapes", []):
            pts = shape["points"]
            cat = shape.get("flags", {}).get("category", "unknown")
            label = shape["label"]
            
            color = COLORS.get(cat, (128, 128, 128))
            draw.rectangle([pts[0][0], pts[0][1], pts[1][0], pts[1][1]], 
                          outline=color, width=3)
            
            short_label = label[:20] + "..." if len(label) > 20 else label
            draw.text((pts[0][0], pts[0][1] - 15), short_label, fill=color)
        
        out_path = vis_dir / f"{json_path.stem}_vis.jpg"
        img.save(out_path)
        count += 1
        
        if count % 50 == 0:
            print(f"   å·²å¤„ç† {count} å¼ ...")
    
    print(f"   âœ… ç”Ÿæˆ {count} å¼ å¯è§†åŒ–å›¾ç‰‡")
    return vis_dir


# ============================================================================
# Step 4: æ‰“åŒ… Dataset
# ============================================================================

def generate_summary(annotations_dir: Path, video_name: str, frame_count: int) -> dict:
    """åˆ†ææ ‡æ³¨æ•°æ®å¹¶ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    from collections import defaultdict
    
    stats = {
        "total_frames": frame_count,
        "annotated_frames": 0,
        "total_objects": 0,
        "categories": defaultdict(int),
        "subcategories": defaultdict(int),
    }
    
    for json_path in sorted(annotations_dir.glob("*.json")):
        with open(json_path, encoding="utf-8") as f:
            data = json.load(f)
        
        shapes = data.get("shapes", [])
        if shapes:
            stats["annotated_frames"] += 1
        
        for shape in shapes:
            stats["total_objects"] += 1
            category = shape.get("flags", {}).get("category", "unknown")
            stats["categories"][category] += 1
            label = shape.get("label", "")
            if label:
                stats["subcategories"][label] += 1
    
    return stats


def create_summary_markdown(stats: dict, video_name: str, fps: int, elapsed_time: float = None) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æ€»ç»“æ–‡æ¡£"""
    from datetime import datetime
    
    lines = []
    lines.append(f"# ğŸ“Š æ•°æ®æ ‡æ³¨æ€»ç»“ - {video_name}")
    lines.append("")
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append(f"**æŠ½å¸§ç‡**: {fps} FPS")
    lines.append(f"**æ ‡æ³¨æ–¹å¼**: å¼‚æ­¥å¹¶è¡Œ (asyncio + httpx)")
    if elapsed_time:
        minutes = int(elapsed_time // 60)
        seconds = elapsed_time % 60
        lines.append(f"**å¤„ç†è€—æ—¶**: {minutes}åˆ†{seconds:.1f}ç§’")
    lines.append("")
    
    lines.append("## ğŸ“ˆ æ¦‚è§ˆç»Ÿè®¡")
    lines.append("")
    lines.append(f"| æŒ‡æ ‡ | æ•°å€¼ |")
    lines.append(f"|------|------|")
    lines.append(f"| æ€»å¸§æ•° | {stats['total_frames']} |")
    lines.append(f"| æœ‰æ ‡æ³¨çš„å¸§ | {stats['annotated_frames']} |")
    lines.append(f"| ç©ºå¸§ï¼ˆæ— æ£€æµ‹ï¼‰ | {stats['total_frames'] - stats['annotated_frames']} |")
    lines.append(f"| æ€»æ£€æµ‹å¯¹è±¡ | {stats['total_objects']} |")
    if stats['annotated_frames'] > 0:
        lines.append(f"| å¹³å‡æ¯å¸§å¯¹è±¡æ•° | {stats['total_objects'] / stats['annotated_frames']:.2f} |")
    lines.append("")
    
    lines.append("## ğŸ·ï¸ ä¸»ç±»åˆ«åˆ†å¸ƒ")
    lines.append("")
    lines.append(f"| ç±»åˆ« | æ•°é‡ | å æ¯” |")
    lines.append(f"|------|------|------|")
    total = stats['total_objects'] or 1
    for cat, count in sorted(stats['categories'].items(), key=lambda x: -x[1]):
        percentage = count / total * 100
        lines.append(f"| {cat} | {count} | {percentage:.1f}% |")
    lines.append("")
    
    if stats['subcategories']:
        lines.append("## ğŸ” ç»†åˆ†ç±»åˆ« Top 20")
        lines.append("")
        lines.append(f"| æ ‡ç­¾ | æ•°é‡ |")
        lines.append(f"|------|------|")
        for label, count in sorted(stats['subcategories'].items(), key=lambda x: -x[1])[:20]:
            display_label = label[:50] + "..." if len(label) > 50 else label
            lines.append(f"| {display_label} | {count} |")
        lines.append("")
    
    lines.append("---")
    lines.append(f"*æ­¤æŠ¥å‘Šç”± video_to_dataset_async.py è‡ªåŠ¨ç”Ÿæˆ*")
    
    return "\n".join(lines)


def create_dataset(video_name: str, video_path: str, frames_dir: Path, annotations_dir: Path, vis_dir: Path, fps: int = 3, elapsed_time: float = None) -> Path:
    """åˆ›å»º Dataset æ–‡ä»¶å¤¹"""
    import shutil
    
    print(f"\nğŸ“¦ Step 4: åˆ›å»º Dataset")
    
    output_base = Path("dataset_output")
    output_base.mkdir(parents=True, exist_ok=True)
    dataset_dir = output_base / f"{video_name}_dataset"
    
    # æ¸…ç†æ—§çš„
    if dataset_dir.exists():
        shutil.rmtree(dataset_dir)
    
    (dataset_dir / "video").mkdir(parents=True, exist_ok=True)
    (dataset_dir / "frames").mkdir(parents=True, exist_ok=True)
    (dataset_dir / "annotations").mkdir(parents=True, exist_ok=True)
    (dataset_dir / "visualized").mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶è§†é¢‘
    video_src = Path(video_path)
    if video_src.exists():
        shutil.copy(video_src, dataset_dir / "video" / video_src.name)
        print(f"   âœ… å¤åˆ¶è§†é¢‘")
    
    # å¤åˆ¶å¸§
    frame_count = 0
    for frame in frames_dir.glob("*.jpg"):
        shutil.copy(frame, dataset_dir / "frames" / frame.name)
        frame_count += 1
    print(f"   âœ… å¤åˆ¶ {frame_count} å¸§")
    
    # å¤åˆ¶æ ‡æ³¨
    ann_count = 0
    for ann in annotations_dir.glob("*.json"):
        shutil.copy(ann, dataset_dir / "annotations" / ann.name)
        ann_count += 1
    print(f"   âœ… å¤åˆ¶ {ann_count} æ ‡æ³¨")
    
    # å¤åˆ¶å¯è§†åŒ–
    if vis_dir and vis_dir.exists():
        vis_count = 0
        for vis in vis_dir.glob("*.jpg"):
            shutil.copy(vis, dataset_dir / "visualized" / vis.name)
            vis_count += 1
        print(f"   âœ… å¤åˆ¶ {vis_count} å¯è§†åŒ–")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print(f"   ğŸ“ ç”Ÿæˆæ ‡æ³¨æ€»ç»“æ–‡æ¡£...")
    stats = generate_summary(dataset_dir / "annotations", video_name, frame_count)
    summary_md = create_summary_markdown(stats, video_name, fps, elapsed_time)
    
    summary_path = dataset_dir / "SUMMARY.md"
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(summary_md)
    print(f"   âœ… ç”Ÿæˆ SUMMARY.md")
    
    # ä¿å­˜ JSON æ ¼å¼çš„ç»Ÿè®¡æ•°æ®
    stats_json = {
        "video_name": video_name,
        "total_frames": stats["total_frames"],
        "annotated_frames": stats["annotated_frames"],
        "total_objects": stats["total_objects"],
        "categories": dict(stats["categories"]),
        "subcategories": dict(stats["subcategories"]),
        "fps": fps
    }
    stats_path = dataset_dir / "stats.json"
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats_json, f, ensure_ascii=False, indent=2)
    print(f"   âœ… ç”Ÿæˆ stats.json")
    
    # å‹ç¼©
    print(f"   ğŸ“¦ åˆ›å»ºå‹ç¼©åŒ…...")
    zip_path = output_base / f"{video_name}_dataset.zip"
    shutil.make_archive(str(dataset_dir), 'zip', str(output_base), f"{video_name}_dataset")
    zip_size = zip_path.stat().st_size / (1024 * 1024)
    print(f"   âœ… {zip_path} ({zip_size:.1f} MB)")
    
    return dataset_dir


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

async def main_async():
    parser = argparse.ArgumentParser(description="å¼‚æ­¥è§†é¢‘åˆ°æ•°æ®é›†æµæ°´çº¿")
    parser.add_argument("--video", type=str, required=True, help="è§†é¢‘æ–‡ä»¶è·¯å¾„ (å¦‚ traffic_sign_data/videos/clips/D1/D1_000.mp4)")
    parser.add_argument("--name", type=str, default=None, help="è¾“å‡ºåç§° (é»˜è®¤ä½¿ç”¨è§†é¢‘æ–‡ä»¶å)")
    parser.add_argument("--fps", type=int, default=3, help="æŠ½å¸§ç‡ (é»˜è®¤ 3)")
    parser.add_argument("--workers", type=int, default=15, help="å¹¶å‘æ•° (é»˜è®¤ 15)")
    parser.add_argument("--skip-extract", action="store_true", help="è·³è¿‡æŠ½å¸§")
    parser.add_argument("--skip-visualize", action="store_true", help="è·³è¿‡å¯è§†åŒ–")
    parser.add_argument("--rag", action="store_true", default=True, help="å¯ç”¨ RAG äº¤é€šæ ‡å¿—ç»†ç²’åº¦åˆ†ç±» (é»˜è®¤å¯ç”¨)")
    parser.add_argument("--no-rag", dest="rag", action="store_false", help="ç¦ç”¨ RAG äº¤é€šæ ‡å¿—ç»†ç²’åº¦åˆ†ç±»")
    args = parser.parse_args()
    
    video_path = Path(args.video)
    
    # è‡ªåŠ¨ç¡®å®šè¾“å‡ºåç§°
    if args.name:
        output_name = args.name
    else:
        output_name = video_path.stem  # å¦‚ D1_000
    
    api_key = os.getenv("ZAI_API_KEY")
    
    if not api_key:
        print("âŒ è¯·è®¾ç½® ZAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    if not video_path.exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print("=" * 70)
    print(f"ğŸš€ å¼‚æ­¥è§†é¢‘æ ‡æ³¨æµæ°´çº¿ - {output_name}")
    print(f"   è§†é¢‘: {video_path}")
    print(f"   FPS: {args.fps} | å¹¶å‘: {args.workers} | æ¨¡å¼: asyncio")
    print("=" * 70)
    
    start_time = time.time()
    
    # Step 1
    if args.skip_extract:
        frames_dir = TEMP_FRAMES_DIR / output_name
        print(f"\nâ­ï¸ è·³è¿‡æŠ½å¸§ï¼Œä½¿ç”¨: {frames_dir}")
    else:
        frames_dir, _ = extract_frames(str(video_path), output_name, args.fps)
        if not frames_dir:
            return
    
    # Step 2
    annotations_dir = await run_labeling_async(frames_dir, output_name, args.workers, api_key, use_rag=args.rag)
    if not annotations_dir:
        return
    
    # Step 3
    if args.skip_visualize:
        vis_dir = None
        print(f"\nâ­ï¸ è·³è¿‡å¯è§†åŒ–")
    else:
        vis_dir = generate_visualizations(frames_dir, annotations_dir, output_name)
    
    # Step 4
    total_time = time.time() - start_time
    dataset_dir = create_dataset(output_name, str(video_path), frames_dir, annotations_dir, vis_dir, fps=args.fps, elapsed_time=total_time)
    
    print("\n" + "=" * 70)
    print(f"ğŸ‰ å®Œæˆï¼æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ ({total_time:.1f}ç§’)")
    print(f"ğŸ“ Dataset: {dataset_dir}/")
    print("=" * 70)


def main():
    asyncio.run(main_async())


if __name__ == "__main__":
    main()

