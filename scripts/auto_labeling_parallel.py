#!/usr/bin/env python3
"""
å¹¶è¡Œç‰ˆè‡ªåŠ¨æ ‡æ³¨è„šæœ¬

ä½¿ç”¨ concurrent.futures å®ç°å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œå¤§å¹…æå‡æ‰¹é‡æ ‡æ³¨é€Ÿåº¦ã€‚
åŸæ¥ 100 å¼ å›¾éœ€è¦ ~15 åˆ†é’Ÿï¼Œç°åœ¨ ~3 åˆ†é’Ÿã€‚

ç”¨æ³•:
    python3 auto_labeling_parallel.py --prefix D2 --limit 50 --workers 5
"""

import os
import json
import base64
import argparse
import time
import uuid  # ç”¨äºç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
from zai import ZaiClient


# ============================================================================
# é…ç½®
# ============================================================================

SIGNS_DIR = Path("examples/signs/highres/png2560px")

def load_sign_candidates():
    """ä»æ ‡å¿—å›¾ç‰‡ç›®å½•åŠ¨æ€åŠ è½½æ‰€æœ‰æ ‡å¿—åç§°"""
    if not SIGNS_DIR.exists():
        return []
    return [f.stem for f in sorted(SIGNS_DIR.glob("*.png"))]

ALL_SIGN_CANDIDATES = load_sign_candidates()


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def get_category(label: str) -> str:
    """æ ¹æ®æ ‡ç­¾è·å–ç²—ç²’åº¦ç±»åˆ«"""
    label_lower = label.lower().replace(" ", "_").replace("-", "_")
    
    if any(p in label_lower for p in ["pedestrian", "person", "people", "child", "cyclist", "crowd"]):
        return "pedestrian"
    if any(v in label_lower for v in ["car", "truck", "bus", "motorcycle", "bicycle", "van", "suv", "taxi", "vehicle"]):
        return "vehicle"
    if any(c in label_lower for c in ["cone", "construction", "barrier", "road_work", "detour"]):
        return "construction"
    if any(s in label_lower for s in ["sign", "speed", "limit", "no_", "traffic", "light", "stop", "give_way", "direction", "exit", "lane", "countdown"]):
        return "traffic_sign"
    return "unknown"


def image_to_base64_url(image_path: str) -> str:
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')
    ext = Path(image_path).suffix.lower()
    mime_type = {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')
    return f"data:{mime_type};base64,{image_data}"


def get_image_size(image_path: str) -> tuple:
    with Image.open(image_path) as img:
        return img.width, img.height


# ============================================================================
# å•å¼ å›¾ç‰‡å¤„ç†å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œï¼‰
# ============================================================================

def classify_sign_rag(client, image_path: str, bbox: list) -> str:
    """RAG äºŒé˜¶æ®µäº¤é€šæ ‡å¿—ç²¾æ’ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆï¼‰"""
    import re
    
    temp_path = None  # ç¡®ä¿ finally å—å¯ä»¥è®¿é—®
    
    try:
        img = Image.open(image_path)
        padding = 10
        x1 = max(0, bbox[0] - padding)
        y1 = max(0, bbox[1] - padding)
        x2 = min(img.width, bbox[2] + padding)
        y2 = min(img.height, bbox[3] + padding)
        
        sign_crop = img.crop((x1, y1, x2, y2))
        # ä½¿ç”¨ uuid ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
        unique_id = uuid.uuid4()
        temp_path = f"/tmp/sign_crop_{unique_id}.jpg"
        sign_crop.save(temp_path, "JPEG")
        
        with open(temp_path, "rb") as f:
            img_data = base64.b64encode(f.read()).decode()
        
        # é˜¶æ®µ1ï¼šåˆ¤æ–­ç±»å‹
        type_prompt = """è¯·åˆ¤æ–­è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„äº¤é€šæ ‡å¿—ï¼š
1. é™é€Ÿæ ‡å¿—ï¼ˆçº¢åœˆç™½åº•ï¼Œä¸­é—´æœ‰æ•°å­—ï¼‰
2. ç¦æ­¢æ ‡å¿—ï¼ˆçº¢åœˆï¼‰
3. è­¦å‘Šæ ‡å¿—ï¼ˆä¸‰è§’å½¢ï¼‰
4. æŒ‡ç¤º/æ–¹å‘æ ‡å¿—ï¼ˆè“è‰²æˆ–ç»¿è‰²ï¼‰
5. å…¶ä»–

åªè¿”å›æ•°å­—ï¼ˆ1-5ï¼‰ã€‚"""
        
        response1 = client.chat.completions.create(
            model="glm-4.6v",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                    {"type": "text", "text": type_prompt}
                ]
            }],
            temperature=0.1
        )
        
        type_response = response1.choices[0].message.content.strip()
        type_match = re.search(r'[1-5]', type_response)
        
        if not type_match:
            return "traffic_sign"
        
        sign_type = type_match.group()
        
        # é˜¶æ®µ2ï¼šç»†èŠ‚è¯†åˆ«
        if sign_type == "1":  # é™é€Ÿ
            detail_prompt = "è¯·è¯†åˆ«è¿™ä¸ªé™é€Ÿæ ‡å¿—ä¸Šçš„æ•°å­—ã€‚åªè¿”å›æ•°å­—ã€‚"
            response2 = client.chat.completions.create(
                model="glm-4.6v",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                        {"type": "text", "text": detail_prompt}
                    ]
                }],
                temperature=0.1
            )
            numbers = re.findall(r'\d+', response2.choices[0].message.content)
            if numbers:
                return f"Speed_limit_{numbers[0]}_km_h"
            return "Speed_limit"
        
        elif sign_type == "4":  # æ–¹å‘/æŒ‡ç¤º
            # æ£€æµ‹æ˜¯å¦ä¸ºè·ç¦»ç‰Œ
            detail_prompt = """è¿™æ˜¯ä¸€ä¸ªæŒ‡ç¤ºæˆ–æ–¹å‘æ ‡å¿—ã€‚è¯·åˆ¤æ–­ï¼š
1. æ–¹å‘æŒ‡ç¤ºç‰Œ
2. é«˜é€Ÿå…¬è·¯æ ‡å¿—
3. å€’è®¡æ—¶è·ç¦»ç‰Œï¼ˆ100m/200m/300mæ–œæ¡ï¼‰
4. å…¶ä»–

åªè¿”å›æ•°å­—ï¼ˆ1-4ï¼‰ã€‚"""
            response2 = client.chat.completions.create(
                model="glm-4.6v",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                        {"type": "text", "text": detail_prompt}
                    ]
                }],
                temperature=0.1
            )
            detail = re.search(r'[1-4]', response2.choices[0].message.content)
            if detail:
                label_map = {
                    "1": "Direction_sign",
                    "2": "Expressway_sign",
                    "3": "100m_Countdown_markers",
                    "4": "Direction_other"
                }
                return label_map.get(detail.group(), "Direction_sign")
            return "Direction_sign"
        
        type_labels = {
            "2": "Prohibition_sign",
            "3": "Warning_sign",
            "5": "traffic_sign"
        }
        return type_labels.get(sign_type, "traffic_sign")
        
    except Exception as e:
        return "traffic_sign"
    
    finally:
        # âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œé˜²æ­¢ç£ç›˜ç©ºé—´æ³„æ¼
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass  # å¿½ç•¥åˆ é™¤å¤±è´¥


def process_single_image(args_tuple):
    """
    å¤„ç†å•å¼ å›¾ç‰‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    
    Args:
        args_tuple: (image_path, api_key, max_retries, use_rag)
    
    Returns:
        (image_path, detections, error)
    """
    image_path, api_key, max_retries, use_rag = args_tuple
    
    try:
        # æ¯ä¸ªçº¿ç¨‹åˆ›å»ºè‡ªå·±çš„ client
        client = ZaiClient(api_key=api_key)
        
        base64_url = image_to_base64_url(image_path)
        width, height = get_image_size(image_path)
        
        prompt = """è¯·æ£€æµ‹å›¾ç‰‡ä¸­çš„ä»¥ä¸‹4ç±»ç‰©ä½“ï¼Œè¿”å›JSONæ ¼å¼ã€‚

## æ£€æµ‹ç±»åˆ«ä¸ç»†ç²’åº¦è¦æ±‚ï¼š
1. è¡Œäººï¼špedestrian, cyclist, child, crowd
2. è½¦è¾†ï¼šcar, truck, bus, motorcycle, bicycle, van, taxiï¼ˆä¸è¦æ ‡æ³¨ç¬¬ä¸€äººç§°ï¼‰
   - ã€é‡è¦ã€‘è¯·è§‚å¯Ÿå°¾ç¯çŠ¶æ€ï¼ˆç»†ç²’åº¦æ ‡æ³¨ï¼‰ï¼š
   - å¦‚æœå°¾ç¯æ˜¾è‘—é«˜äº®ï¼ˆçº¢è‰²åˆ¹è½¦ç¯äº®èµ·ï¼‰ï¼Œlabel è®°ä¸º "car_braking"
   - å¦‚æœå·¦ä¾§ç¯æ¯”å³ä¾§äº®æˆ–å‘ˆé»„è‰²/æ©™è‰²ï¼Œlabel è®°ä¸º "car_turn_left"
   - å¦‚æœå³ä¾§ç¯æ¯”å·¦ä¾§äº®æˆ–å‘ˆé»„è‰²/æ©™è‰²ï¼Œlabel è®°ä¸º "car_turn_right"
   - å¦‚æœåŒä¾§é»„è‰²ç¯åŒæ—¶äº®èµ·ï¼ˆåŒé—ªï¼‰ï¼Œlabel è®°ä¸º "car_hazard_lights"
   - æ­£å¸¸è¡Œé©¶æˆ–çœ‹ä¸æ¸…å°¾ç¯çŠ¶æ€ï¼Œä¿æŒ "car"
3. äº¤é€šæ ‡å¿—ï¼štraffic_sign
4. æ–½å·¥æ ‡å¿—ï¼štraffic_cone, construction_barrier

## è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
[
  {"label": "car_braking", "bbox_2d": [100, 200, 300, 400]},
  {"label": "traffic_sign", "bbox_2d": [50, 50, 80, 80]}
]

å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œè¿”å› []
åªè¿”å›JSONæ•°ç»„ï¼"""

        for attempt in range(max_retries):
            try:
                response = client.chat.completions.create(
                    model="glm-4.6v",
                    messages=[{
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": base64_url}},
                            {"type": "text", "text": prompt}
                        ]
                    }]
                )
                
                result_text = response.choices[0].message.content.strip()
                
                if not result_text:
                    if attempt < max_retries - 1:
                        continue
                    return (image_path, [], None)
                
                # è§£æ JSON
                if "```json" in result_text:
                    json_str = result_text.split("```json")[1].split("```")[0].strip()
                elif "```" in result_text:
                    json_str = result_text.split("```")[1].split("```")[0].strip()
                elif "[" in result_text:
                    json_str = result_text[result_text.find("["):result_text.rfind("]")+1]
                else:
                    json_str = result_text.strip()
                
                if json_str == "[]" or json_str == "":
                    return (image_path, [], None)
                
                # ä¿®å¤æˆªæ–­ JSON
                if json_str and not json_str.endswith("]"):
                    last_complete = json_str.rfind("},")
                    if last_complete > 0:
                        json_str = json_str[:last_complete+1] + "]"
                
                detections = json.loads(json_str)
                processed = []
                
                for det in detections:
                    if "label" not in det or "bbox_2d" not in det:
                        continue
                    
                    raw_bbox = det["bbox_2d"]
                    bbox = [
                        int(round(raw_bbox[0] / 1000 * width)),
                        int(round(raw_bbox[1] / 1000 * height)),
                        int(round(raw_bbox[2] / 1000 * width)),
                        int(round(raw_bbox[3] / 1000 * height))
                    ]
                    
                    label = det["label"].lower().replace(" ", "_").replace("-", "_")
                    category = get_category(label)
                    
                    # RAG ç»†ç²’åº¦åˆ†ç±»ï¼ˆä»…äº¤é€šæ ‡å¿—ï¼‰
                    if use_rag and category == "traffic_sign" and label in ["traffic_sign", "sign"]:
                        label = classify_sign_rag(client, image_path, bbox)
                        category = "traffic_sign"
                    
                    processed.append({
                        "label": label,
                        "category": category,
                        "bbox": bbox
                    })
                
                return (image_path, processed, None)
                
            except json.JSONDecodeError:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    continue
                return (image_path, [], "JSON parse error")
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))  # æŒ‡æ•°é€€é¿ï¼Œé¿å… 429 é”™è¯¯
                    continue
                return (image_path, [], str(e))
        
        return (image_path, [], "Max retries exceeded")
    
    except Exception as e:
        return (image_path, [], str(e))


# ============================================================================
# è¾“å‡ºå‡½æ•°
# ============================================================================

def to_xanylabeling_format(detections: list, image_path: str) -> dict:
    """è½¬æ¢ä¸º X-AnyLabeling æ ¼å¼"""
    width, height = get_image_size(image_path)
    
    shapes = []
    for det in detections:
        shapes.append({
            "label": det["label"],
            "text": det["label"],
            "points": [
                [det["bbox"][0], det["bbox"][1]],
                [det["bbox"][2], det["bbox"][3]]
            ],
            "group_id": None,
            "shape_type": "rectangle",
            "flags": {"category": det["category"]}
        })
    
    return {
        "version": "0.4.1",
        "flags": {},
        "shapes": shapes,
        "imagePath": Path(image_path).name,
        "imageData": None,
        "imageHeight": height,
        "imageWidth": width
    }


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="å¹¶è¡Œç‰ˆè‡ªåŠ¨æ ‡æ³¨è„šæœ¬")
    parser.add_argument("--prefix", type=str, required=True, help="å›¾ç‰‡å‰ç¼€ (å¦‚ D1, D2)")
    parser.add_argument("--limit", type=int, default=None, help="é™åˆ¶å¤„ç†æ•°é‡")
    parser.add_argument("--workers", type=int, default=5, help="å¹¶è¡Œçº¿ç¨‹æ•° (é»˜è®¤ 5)")
    parser.add_argument("--rag", action="store_true", help="å¯ç”¨ RAG ç»†ç²’åº¦åˆ†ç±»")
    parser.add_argument("--images-dir", type=str, default="test_images/extracted_frames")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    api_key = os.getenv("ZAI_API_KEY")
    if not api_key:
        print("âŒ è¯·è®¾ç½® ZAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # è·å–å›¾ç‰‡åˆ—è¡¨
    images_dir = Path(args.images_dir)
    image_files = sorted(images_dir.glob(f"{args.prefix}_*.jpg"))
    
    if args.limit:
        image_files = image_files[:args.limit]
    
    if not image_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {args.prefix} å¼€å¤´çš„å›¾ç‰‡")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    rag_suffix = "_rag" if args.rag else ""
    output_dir = Path(f"output/{args.prefix.lower()}_annotations{rag_suffix}")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å‡†å¤‡å‚æ•°
    width, height = get_image_size(str(image_files[0]))
    task_args = [(str(img), api_key, 3, args.rag) for img in image_files]
    
    print("=" * 70)
    print(f"ğŸš€ å¹¶è¡Œè‡ªåŠ¨æ ‡æ³¨ - {args.prefix} series")
    print(f"   ğŸ“ Images: {len(image_files)} | Resolution: {width}x{height}")
    print(f"   ğŸ”§ Workers: {args.workers} ä¸ªå¹¶è¡Œçº¿ç¨‹")
    print(f"   ğŸ” RAG Mode: {'âœ… Enabled' if args.rag else 'âŒ Disabled'}")
    print("=" * 70)
    
    start_time = time.time()
    
    # ç»Ÿè®¡
    stats = {"pedestrian": 0, "vehicle": 0, "traffic_sign": 0, "construction": 0}
    success_count = 0
    error_count = 0
    
    # å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        futures = {executor.submit(process_single_image, arg): arg[0] for arg in task_args}
        
        for i, future in enumerate(as_completed(futures)):
            image_path = futures[future]
            image_name = Path(image_path).name
            
            try:
                _, detections, error = future.result()
                
                if error:
                    print(f"  âš ï¸ [{i+1}/{len(image_files)}] {image_name}: {error}")
                    error_count += 1
                else:
                    # ç»Ÿè®¡
                    for det in detections:
                        stats[det["category"]] = stats.get(det["category"], 0) + 1
                    
                    # ä¿å­˜
                    annotation = to_xanylabeling_format(detections, image_path)
                    output_path = output_dir / f"{Path(image_path).stem}.json"
                    with open(output_path, "w", encoding="utf-8") as f:
                        json.dump(annotation, f, ensure_ascii=False, indent=2)
                    
                    emoji = "âœ…" if detections else "âšª"
                    print(f"  {emoji} [{i+1}/{len(image_files)}] {image_name}: {len(detections)} objects")
                    success_count += 1
                    
            except Exception as e:
                print(f"  âŒ [{i+1}/{len(image_files)}] {image_name}: {e}")
                error_count += 1
    
    elapsed = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ“Š Statistics:")
    for cat, count in stats.items():
        print(f"   {cat}: {count}")
    print(f"\nâ±ï¸ Time: {elapsed:.1f}s ({elapsed/len(image_files):.2f}s per image)")
    print(f"âœ… Success: {success_count} | âš ï¸ Errors: {error_count}")
    print(f"ğŸ“ Saved to: {output_dir}")
    print("=" * 70)


if __name__ == "__main__":
    main()
