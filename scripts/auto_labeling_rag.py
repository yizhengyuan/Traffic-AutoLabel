#!/usr/bin/env python3
"""
GLM-4.6V + RAG å¢å¼ºæ ‡æ³¨è„šæœ¬

åŠŸèƒ½ï¼š
1. åŸºç¡€æ£€æµ‹ï¼šè¯†åˆ«è¡Œäººã€è½¦è¾†ã€äº¤é€šæ ‡å¿—ã€æ–½å·¥æ ‡å¿—
2. RAG ç²¾æ’ï¼šå¯¹äº¤é€šæ ‡å¿—è¿›è¡Œç»†ç²’åº¦åˆ†ç±»ï¼ˆåŒ¹é… 188 ç§æ ‡å‡†æ ‡å¿—ï¼‰

ç”¨æ³•:
    python3 auto_labeling_rag.py --prefix D1 --limit 10
"""

import os
import json
import base64
import argparse
from pathlib import Path
from PIL import Image
from zai import ZaiClient


# ============================================================================
# æ ‡å‡†äº¤é€šæ ‡å¿—å€™é€‰åº“ï¼ˆåŠ¨æ€åŠ è½½ 188 ä¸ªé¦™æ¸¯é“è·¯æ ‡å¿—ï¼‰
# ============================================================================

SIGNS_DIR = Path("examples/signs/highres/png2560px")

def load_sign_candidates():
    """ä»æ ‡å¿—å›¾ç‰‡ç›®å½•åŠ¨æ€åŠ è½½æ‰€æœ‰æ ‡å¿—åç§°"""
    if not SIGNS_DIR.exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ ‡å¿—ç›®å½•: {SIGNS_DIR}")
        return []
    
    candidates = []
    for f in sorted(SIGNS_DIR.glob("*.png")):
        # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
        label = f.stem  # ä¾‹å¦‚: "Speed_limit_(in_km_h)"
        candidates.append(label)
    
    return candidates

# åŠ è½½æ‰€æœ‰å€™é€‰æ ‡å¿—
ALL_SIGN_CANDIDATES = load_sign_candidates()


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def get_category(label: str) -> str:
    """æ ¹æ®æ ‡ç­¾è·å–ç²—é¢—ç²’åº¦ç±»åˆ«"""
    label_lower = label.lower().replace(" ", "_").replace("-", "_")
    
    if any(p in label_lower for p in ["pedestrian", "person", "people", "child", "cyclist", "crowd"]):
        return "pedestrian"
    if any(v in label_lower for v in ["car", "truck", "bus", "motorcycle", "bicycle", "van", "suv", "taxi", "vehicle"]):
        return "vehicle"
    if any(c in label_lower for c in ["cone", "construction", "barrier", "road_work", "detour"]):
        return "construction"
    if any(s in label_lower for s in ["sign", "speed", "limit", "no_", "traffic", "light", "stop", "give_way", "direction", "exit", "lane"]):
        return "traffic_sign"
    return "unknown"


def image_to_base64_url(image_path: str) -> str:
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')
    ext = Path(image_path).suffix.lower()
    mime_type = {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')
    return f"data:{mime_type};base64,{image_data}"


def get_image_size(image_path: str) -> tuple:
    with Image.open(image_path) as img:
        return img.width, img.height


# ============================================================================
# RAG ç»†ç²’åº¦åˆ†ç±»
# ============================================================================

def classify_sign_with_rag(client: ZaiClient, image_path: str, bbox: list) -> str:
    """
    å¯¹æ£€æµ‹åˆ°çš„äº¤é€šæ ‡å¿—åŒºåŸŸè¿›è¡Œ RAG ç»†ç²’åº¦åˆ†ç±»
    
    Args:
        client: ZaiClient å®ä¾‹
        image_path: åŸå§‹å›¾ç‰‡è·¯å¾„
        bbox: æ ‡å¿—åŒºåŸŸ [x1, y1, x2, y2]
        
    Returns:
        ç»†ç²’åº¦æ ‡ç­¾
    """
    # æ‰©å¤§è£å‰ªåŒºåŸŸï¼ˆé¿å…è¾¹ç•Œå¤ªç´§ï¼‰
    x1, y1, x2, y2 = bbox
    padding = 5
    
    img = Image.open(image_path)
    x1 = max(0, x1 - padding)
    y1 = max(0, y1 - padding)
    x2 = min(img.width, x2 + padding)
    y2 = min(img.height, y2 + padding)
    
    # è£å‰ªæ ‡å¿—åŒºåŸŸ
    sign_crop = img.crop((x1, y1, x2, y2))
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = "/tmp/sign_crop.jpg"
    sign_crop.save(temp_path, "JPEG")
    
    # è¯»å–å¹¶ç¼–ç 
    with open(temp_path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode()
    
    # æ„å»ºå€™é€‰åˆ—è¡¨
    candidate_list = "\n".join([f"{i+1}. {c}" for i, c in enumerate(ALL_SIGN_CANDIDATES)])
    
    prompt = f"""è¯·ä»”ç»†è§‚å¯Ÿè¿™ä¸ªäº¤é€šæ ‡å¿—ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ï¼š

{candidate_list}

è§„åˆ™ï¼š
1. è§‚å¯Ÿæ ‡å¿—çš„é¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ã€æ•°å­—
2. å¦‚æœæ˜¯é™é€Ÿæ ‡å¿—ï¼Œè¯·è¯†åˆ«å…·ä½“æ•°å­—
3. å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å› "traffic_sign"

è¯·åªè¿”å›é€‰é¡¹ç¼–å·ï¼ˆå¦‚ 1ã€2ã€3ï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

    try:
        response = client.chat.completions.create(
            model="glm-4.6v",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                    {"type": "text", "text": prompt}
                ]
            }]
        )
        
        choice = response.choices[0].message.content.strip()
        
        # è§£æé€‰æ‹©
        base_label = "traffic_sign"
        try:
            import re
            numbers = re.findall(r'\d+', choice)
            if numbers:
                idx = int(numbers[0]) - 1
                if 0 <= idx < len(ALL_SIGN_CANDIDATES):
                    base_label = ALL_SIGN_CANDIDATES[idx]
        except:
            pass
        
        # ============================================================
        # äºŒé˜¶æ®µç²¾æ’ï¼šå¯¹é€šç”¨æ ‡å¿—è¿›ä¸€æ­¥è¯†åˆ«å…·ä½“ç»†èŠ‚
        # ============================================================
        generic_signs = {
            "Speed_limit_(in_km_h)": {
                "question": "è¯·è¯†åˆ«è¿™ä¸ªé™é€Ÿæ ‡å¿—ä¸Šæ˜¾ç¤ºçš„å…·ä½“æ•°å­—ï¼ˆå¦‚ 20, 30, 50, 70, 100ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                "format": "Speed_limit_{}_km_h"
            },
            "Variable_speed_limit_(in_km_h)": {
                "question": "è¯·è¯†åˆ«è¿™ä¸ªå¯å˜é™é€Ÿæ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æ•°å­—ã€‚åªè¿”å›æ•°å­—ã€‚",
                "format": "Variable_speed_limit_{}_km_h"
            },
            "Distance_as_shown_to_hazard": {
                "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„è·ç¦»æ•°å­—ï¼ˆå•ä½ï¼šç±³ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                "format": "Distance_{}_m_to_hazard"
            },
            "Maximum_height_as_shown_(in_metres)": {
                "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æœ€å¤§é«˜åº¦é™åˆ¶ï¼ˆå•ä½ï¼šç±³ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                "format": "Maximum_height_{}_m"
            },
            "Maximum_payload_as_shown_(in_tonnes)": {
                "question": "è¯·è¯†åˆ«æ ‡å¿—ä¸Šæ˜¾ç¤ºçš„æœ€å¤§è½½é‡é™åˆ¶ï¼ˆå•ä½ï¼šå¨ï¼‰ã€‚åªè¿”å›æ•°å­—ã€‚",
                "format": "Maximum_payload_{}_tonnes"
            }
        }
        
        if base_label in generic_signs:
            detail_info = generic_signs[base_label]
            print(f"    ğŸ” äºŒé˜¶æ®µç²¾æ’ï¼šè¯†åˆ«å…·ä½“æ•°å­—...")
            
            detail_response = client.chat.completions.create(
                model="glm-4.6v",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}"}},
                        {"type": "text", "text": detail_info["question"]}
                    ]
                }]
            )
            
            detail_text = detail_response.choices[0].message.content.strip()
            
            # æå–æ•°å­—
            import re
            detail_numbers = re.findall(r'\d+', detail_text)
            if detail_numbers:
                specific_value = detail_numbers[0]
                refined_label = detail_info["format"].format(specific_value)
                print(f"    â†’ è¯†åˆ«åˆ°æ•°å­—: {specific_value}, æœ€ç»ˆæ ‡ç­¾: {refined_label}")
                return refined_label
        
        return base_label
        
    except Exception as e:
        print(f"    âš ï¸ RAG åˆ†ç±»å¤±è´¥: {e}")
        return "traffic_sign"


# ============================================================================
# ä¸»æ£€æµ‹å‡½æ•°
# ============================================================================

def detect_objects(client: ZaiClient, image_path: str, use_rag: bool = False, max_retries: int = 3) -> list:
    """æ£€æµ‹å›¾ç‰‡ä¸­çš„ç›®æ ‡"""
    base64_url = image_to_base64_url(image_path)
    width, height = get_image_size(image_path)
    
    prompt = """è¯·æ£€æµ‹å›¾ç‰‡ä¸­çš„ä»¥ä¸‹4ç±»ç‰©ä½“ï¼Œè¿”å›JSONæ ¼å¼ã€‚

## æ£€æµ‹ç±»åˆ«ï¼ˆä½¿ç”¨è‹±æ–‡æ ‡ç­¾ï¼‰ï¼š
1. è¡Œäººï¼špedestrian, cyclist, child
   - å¦‚æœè¡Œäººå¾ˆå¤šï¼ˆè¶…è¿‡5äººï¼‰ï¼Œå¯ä»¥ç”¨ crowd æ ‡ç­¾æ¡†ä½æ•´ä¸ªäººç¾¤åŒºåŸŸ
2. è½¦è¾†ï¼šcar, truck, bus, motorcycle, bicycle, van, taxiï¼ˆä¸è¦æ ‡æ³¨ç¬¬ä¸€äººç§°æ‘©æ‰˜è½¦/è‡ªè¡Œè½¦ï¼‰
3. äº¤é€šæ ‡å¿—ï¼štraffic_signï¼ˆåç»­ä¼šç”¨ RAG ç»†åˆ†ï¼‰
4. æ–½å·¥æ ‡å¿—ï¼štraffic_cone, construction_barrier

## è¿”å›æ ¼å¼ï¼š
[{"label": "car", "bbox_2d": [xmin, ymin, xmax, ymax]}, {"label": "traffic_sign", "bbox_2d": [x1, y1, x2, y2]}]

å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œè¿”å› []

é‡è¦ï¼šåªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼"""

    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="glm-4.6v",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": base64_url}},
                        {"type": "text", "text": prompt}
                    ]
                }]
            )
            
            result_text = response.choices[0].message.content.strip()
            
            if not result_text or result_text.strip() == "":
                if attempt < max_retries - 1:
                    print(f"  âš ï¸ Empty response, retrying ({attempt + 2}/{max_retries})...")
                    continue
                return []
            
            # è§£æ JSON
            if "```json" in result_text:
                json_str = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                json_str = result_text.split("```")[1].split("```")[0].strip()
            elif "[" in result_text:
                json_str = result_text[result_text.find("["):result_text.rfind("]")+1]
            else:
                json_str = result_text.strip()
            
            if json_str == "[]" or json_str == "":
                return []
            
            # ä¿®å¤è¢«æˆªæ–­çš„ JSON
            if json_str and not json_str.endswith("]"):
                last_complete = json_str.rfind("},")
                if last_complete > 0:
                    json_str = json_str[:last_complete+1] + "]"
                    print(f"  âš ï¸ JSON truncated, recovered {json_str.count('label')} objects")
            
            detections = json.loads(json_str)
            processed = []
            
            for det in detections:
                if "label" not in det or "bbox_2d" not in det:
                    continue
                    
                raw_bbox = det["bbox_2d"]
                bbox = [
                    int(round(raw_bbox[0] / 1000 * width)),
                    int(round(raw_bbox[1] / 1000 * height)),
                    int(round(raw_bbox[2] / 1000 * width)),
                    int(round(raw_bbox[3] / 1000 * height))
                ]
                
                label = det["label"].lower().replace(" ", "_").replace("-", "_")
                category = get_category(label)
                
                # RAG ç»†ç²’åº¦åˆ†ç±»ï¼ˆä»…å¯¹äº¤é€šæ ‡å¿—ï¼‰
                if use_rag and category == "traffic_sign" and label in ["traffic_sign", "sign"]:
                    print(f"    ğŸ” RAG ç²¾æ’äº¤é€šæ ‡å¿—...")
                    label = classify_sign_with_rag(client, image_path, bbox)
                    print(f"    â†’ {label}")
                
                processed.append({
                    "label": label,
                    "category": category,
                    "bbox": bbox
                })
            
            return processed
            
        except json.JSONDecodeError as e:
            if attempt < max_retries - 1:
                print(f"  âš ï¸ JSON parse error, retrying ({attempt + 2}/{max_retries})...")
                continue
            print(f"  âš ï¸ JSON parse error after {max_retries} attempts: {e}")
            return []
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"  âš ï¸ Error: {e}, retrying ({attempt + 2}/{max_retries})...")
                continue
            return []
    
    return []


# ============================================================================
# è¾“å‡ºå‡½æ•°
# ============================================================================

def to_xanylabeling_format(detections: list, image_path: str) -> dict:
    """è½¬æ¢ä¸º X-AnyLabeling æ ¼å¼"""
    width, height = get_image_size(image_path)
    
    shapes = []
    for det in detections:
        shapes.append({
            "label": det["label"],
            "text": det["label"],
            "points": [
                [det["bbox"][0], det["bbox"][1]],
                [det["bbox"][2], det["bbox"][3]]
            ],
            "group_id": None,
            "shape_type": "rectangle",
            "flags": {"category": det["category"]}
        })
    
    return {
        "version": "0.4.1",
        "flags": {},
        "shapes": shapes,
        "imagePath": Path(image_path).name,
        "imageData": None,
        "imageHeight": height,
        "imageWidth": width
    }


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="GLM-4.6V + RAG å¢å¼ºæ ‡æ³¨")
    parser.add_argument("--prefix", type=str, required=True, help="å›¾ç‰‡å‰ç¼€ (å¦‚ D1, D2)")
    parser.add_argument("--limit", type=int, default=None, help="é™åˆ¶å¤„ç†æ•°é‡")
    parser.add_argument("--rag", action="store_true", help="å¯ç”¨ RAG ç»†ç²’åº¦åˆ†ç±»")
    parser.add_argument("--images-dir", type=str, default="test_images/extracted_frames")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    api_key = os.getenv("ZAI_API_KEY")
    if not api_key:
        print("âŒ è¯·è®¾ç½® ZAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    client = ZaiClient(api_key=api_key)
    
    # è·å–å›¾ç‰‡åˆ—è¡¨
    images_dir = Path(args.images_dir)
    image_files = sorted(images_dir.glob(f"{args.prefix}_*.jpg"))
    
    if args.limit:
        image_files = image_files[:args.limit]
    
    if not image_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {args.prefix} å¼€å¤´çš„å›¾ç‰‡")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(f"output/{args.prefix.lower()}_annotations_rag")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç»Ÿè®¡
    width, height = get_image_size(str(image_files[0]))
    stats = {"pedestrian": 0, "vehicle": 0, "traffic_sign": 0, "construction": 0}
    
    print("=" * 70)
    print(f"ğŸ·ï¸  GLM-4.6V {'+ RAG ' if args.rag else ''}Auto Labeling - {args.prefix} series")
    print(f"   Images: {len(image_files)} | Resolution: {width}x{height}")
    print(f"   RAG Mode: {'âœ… Enabled' if args.rag else 'âŒ Disabled'}")
    print("=" * 70)
    
    for i, img_path in enumerate(image_files):
        print(f"\nğŸ“· [{i+1}/{len(image_files)}] {img_path.name}")
        print("-" * 50)
        
        # æ£€æµ‹
        detections = detect_objects(client, str(img_path), use_rag=args.rag)
        
        # è¾“å‡º
        labels = [d["label"] for d in detections]
        categories = [d["category"] for d in detections]
        
        print(f"  âœ… Detected {len(detections)} objects:")
        for det in detections:
            emoji = {"pedestrian": "ğŸ”´", "vehicle": "ğŸŸ¢", "traffic_sign": "ğŸ”µ", "construction": "ğŸŸ "}.get(det["category"], "âšª")
            print(f"     {emoji} {det['label']} [{det['category']}] {det['bbox']}")
            stats[det["category"]] = stats.get(det["category"], 0) + 1
        
        # ä¿å­˜
        annotation = to_xanylabeling_format(detections, str(img_path))
        output_path = output_dir / f"{img_path.stem}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(annotation, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š Statistics:")
    for cat, count in stats.items():
        print(f"   {cat}: {count}")
    print(f"ğŸ“ Annotations saved to: {output_dir}")
    print("=" * 70)


if __name__ == "__main__":
    main()
